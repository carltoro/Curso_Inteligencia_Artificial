{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNd2kU5PhA0lQ1haRUfGwnY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Práctica 4b: Problemas de Clasificación, Varios Algoritmos**\n","\n","Curso: Inteligencia Artificial para Ingenieros\n","\n","Prof. Carlos Toro N. (carlos.toro.ing@gmail.com)\n","\n","2022"],"metadata":{"id":"DV45IZ9474vp"}},{"cell_type":"markdown","source":["**Introducción**"],"metadata":{"id":"gcYaBcWu8NH4"}},{"cell_type":"markdown","source":["En esta práctica continuaremos revisando algoritmos de clasificación y además profundizaremos en temas como hiperparámetros de un modelo y sus ajustes."],"metadata":{"id":"MYwBZnFIDoQt"}},{"cell_type":"markdown","source":["**Dentro de los temas que veremos están:**\n","\n","1. Búsqueda de hiperparámetros\n","2. Árboles de decisión\n","3. Varios algoritmos y pipeline completo de clasificación, ejercicios resueltos.\n","4. Ejercicios propuestos."],"metadata":{"id":"WyqQiDJb8RI3"}},{"cell_type":"markdown","source":["## 1. Búsqueda de hiperparámetros\n","\n","En las prácticas anteriores vimos coomo cargar datos, crear, entrenar y predecir e incluso evaluar el desempeño y capacidad de generalización de modelos predictivos. Aún así, no cambiamos los (hiper) parámetros de los modelos que pueden ser ajustados cuando se crea una instancia de estos. Por ejemplo, para el modelo de k-vecinos más cercanos, `scikit learn` asume por defecto el parámetro: `n_neighbors=5`.\n","\n","Estos parámetros son llamados **hiperparámetros**, y son usados para controlar el proceso de aprendizaje, por ejemplo el valro k de vecinos en el algoritmo KNN sería un hiperparámetro. Estos son especificados por el usuario, de forma manual o con alguna estrategia de búsqueda (ej. exhaustiva o aleatoria, entre otras), y no se pueden estimar desde los datos. No confundir con los otros parámetros que definen el modelo en si mismo y que se optimizan durante el entrenamiento, por ej. la pendiente y coeficiente de posición son los parámetros que definen un modelo de regresión lineal simple $y = mx + b$."],"metadata":{"id":"Is952HwcNu_K"}},{"cell_type":"markdown","source":["Para ejemplificar la búsqueda de hiperparámetros, lo haremos con el algoritmo KNN (`KNeighborsClassifier` en sklearn), un conjunto de datos multivariado: el de  [Fisher's iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris), de especies de flores iris y la función `GridSearchCV` para encontrar los hiperparámetros óptimos dentro de un conjunto de valores propuestos por el usurio."],"metadata":{"id":"vZtI5UJNVPJl"}},{"cell_type":"markdown","source":["**PREVIO:** Importaciones necesarios para la práctica"],"metadata":{"id":"lMJMHb-BsmHM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# imports de sklearn\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"APgd5T4nsvPu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Importemos y exploremos el dataset\n","\n"],"metadata":{"id":"jE5gcTZEWltV"}},{"cell_type":"markdown","source":["El conjunto de datos de flores iris es un conjunto da datos multivariado y es uno de los más populares a nivel introductorio del machine learning. Este conjunto de datos contiene 150 muestras igualmente distribuidas en tres especies de flores iris: iris setosa, iris virginica, iris versicolor. Cada muestra consiste de 4 atribuos/características/variables/features: la longitud y ancho, en centímetros, del sépalo y pétalo. La tarea es predecir a qué clase pertenece una planta de iris no identificada en base a medicioens del pétalo y sépalo.\n","<center><img src=https://www.aifunded.es/images/iris.png width=\"650\"></center>"],"metadata":{"id":"HFzyGIBzto_c"}},{"cell_type":"code","source":["# url para el dataset Iris\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","\n","# Asignamos nombres a las columnas del dataset\n","names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n","\n","# Leemos el dataset\n","df = pd.read_csv(url, names=names)\n","\n","CLASS_NAMES = df[\"Class\"].unique()\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dFF24tAaW4Da","executionInfo":{"status":"ok","timestamp":1665701400243,"user_tz":180,"elapsed":518,"user":{"displayName":"T","userId":"08291709992970270339"}},"outputId":"17ce99bd-ce13-4238-88f9-8a0caff677bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sepal-length  sepal-width  petal-length  petal-width        Class\n","0           5.1          3.5           1.4          0.2  Iris-setosa\n","1           4.9          3.0           1.4          0.2  Iris-setosa\n","2           4.7          3.2           1.3          0.2  Iris-setosa\n","3           4.6          3.1           1.5          0.2  Iris-setosa\n","4           5.0          3.6           1.4          0.2  Iris-setosa"],"text/html":["\n","  <div id=\"df-b339dfeb-9569-4072-8db7-782be6540502\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal-length</th>\n","      <th>sepal-width</th>\n","      <th>petal-length</th>\n","      <th>petal-width</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b339dfeb-9569-4072-8db7-782be6540502')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b339dfeb-9569-4072-8db7-782be6540502 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b339dfeb-9569-4072-8db7-782be6540502');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# estará realmente equilibrado el dataset?\n","df['Class'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhMGfpLozeD1","executionInfo":{"status":"ok","timestamp":1665701420978,"user_tz":180,"elapsed":240,"user":{"displayName":"T","userId":"08291709992970270339"}},"outputId":"220976af-fdc9-4660-adb8-42ae0f63dac7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Iris-setosa        50\n","Iris-versicolor    50\n","Iris-virginica     50\n","Name: Class, dtype: int64"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Gráficos de disepersión de las variables e histogramas\n"],"metadata":{"id":"KwnG_cx703wT"}},{"cell_type":"code","source":["sns.pairplot(df, hue='Class')"],"metadata":{"id":"ZHOyr8B61Mvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenando el modelo con sus parámetros por defecto\n","Primero creamos una instancia del modelo y luego lo entrenamos usando una estrategia de validación cruzada para evaluar su desempeño."],"metadata":{"id":"2tmJmKTDWopS"}},{"cell_type":"code","source":["# Datos\n","X = df.iloc[:,:-1].values\n","y = df['Class'].values\n","\n","# Definción modelo y validación cruzada\n","KNN        = KNeighborsClassifier() # generamos una instancia del modelo con sus parámetros por defecto, en particular, n_neighbors = 5 (default)\n","CV         = KFold(n_splits = 10, shuffle = True, random_state = 1)# definimos el tipo de estrategia de validación cruzada, KFold en este caso con 10 folds y con reordanmiento aleatorio de los datos originales\n","cv_results = cross_validate(KNN, X, y, cv = CV, scoring='accuracy', return_train_score=True)# aplicamos la estrategia\n","\n","# Resultados\n","print(f\"El promedio del accuracy (y su desviación estándar) en los conjuntos de prueba de validación cruzada, con KNN usando 5 vecinos es: \"\n","      f\"{cv_results['test_score'].mean():.2f} ({cv_results['test_score'].std():.2f})\")"],"metadata":{"id":"9IfMSO0b1nPI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Qué sucede si modificamos el hiperparámetro de número de vecinos del algoritmo?"],"metadata":{"id":"6njFuh5rOCnc"}},{"cell_type":"code","source":["N_VECINOS = 3\n","KNN        = KNeighborsClassifier(n_neighbors = N_VECINOS)\n","cv_results = cross_validate(KNN, X, y, cv = CV, scoring='accuracy', return_train_score=True)\n","\n","print(f\"El promedio del accuracy (y su desviación estándar) en los conjuntos de prueba de validación cruzada, con KNN usando {N_VECINOS} vecinos es: \"\n","      f\"{cv_results['test_score'].mean():.2f} ({cv_results['test_score'].std():.2f})\")"],"metadata":{"id":"zlUEKJiL5ftg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos como con cambiar este hiperparámetro manualmente mejoramos el resultado. Automaticemos este proceso de búsqueda y encontremos hiperparámetros óptimos del modelo. Para esto, usaremos la función `GridSearchCV` de  `sklearn`.\n","\n","Antes de esto, cómo saber que hiperparámetros podemos ajustar?:\n","\n","1. Mirando la documentación de los modelos en la página de scikit learn o\n","2. usando el método `get_params` disponible en los modelos de scikit learn para listar los parámetros disponibles y sus valores en una variable tipo diccionario. Igualmente se recomienda revisar la documentación para entender el significado de los parámetros indicados.\n","\n","Por ejemplo, para el modelo KNN definido anteriormente, los parámetros disponibles son (notar que se despliegan con los valores que se ajusatron más arriba):"],"metadata":{"id":"_vhtuhmh6Xf0"}},{"cell_type":"code","source":["KNN.get_params()"],"metadata":{"id":"Poh9Can28gB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para implementar la estrategia, especificamos `param_grid =`, el cual es un diccionario que mapea el mombre del hiperparámetro (e.g., `n_neighbors`) a una lista de valores a probar. El modelo con la métrica score más alta se guarda en `.best_estimator_`. Notar que el número de modelos que se probarán será igual al número de combinaciones de valores de hiperparámetros definidos, en el ejemplo de más abajo, se tiene un total de 20x4 combinaciones. Esto hace computacionalmente costosa la estrategia."],"metadata":{"id":"Q1fTWgAY9nYe"}},{"cell_type":"code","source":["#Dividamos los conjuntos de datos en entrenamiento y test previo a implementar la estrategia\n","data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"uQbq5PNsevY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_knn = KNeighborsClassifier()\n","\n","# GridSearchCV reemplazará n_neighbors y metric por los valores en param_grid.\n","PARAM_GRID  = {\"n_neighbors\": range(1, 21),\n","               \"metric\": [\"minkowski\",\"euclidean\",\"manhattan\",\"cosine\"]}#medida de distancia entre puntos\n","knn_grid_search = GridSearchCV(model_knn,\n","                               param_grid= PARAM_GRID,\n","                               scoring=\"accuracy\",\n","                               cv=10)# implementa internamente validación cruzada para encontrar la mejor combinación de hiperparámetros\n","knn_grid_search.fit(data_train, target_train)# ajustamos el modelo usando la estrategia anterior"],"metadata":{"id":"rmUSxxJu6G1r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exploremos algunos de los resultados obtenidos para las combinaciones de parámetros que se usaron:"],"metadata":{"id":"XQbkavULVU1Y"}},{"cell_type":"code","source":["cv_results = pd.DataFrame(knn_grid_search.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n","cv_results[[\n","    \"param_metric\",\n","    \"param_n_neighbors\",\n","    \"mean_test_score\",\n","    \"std_test_score\",\n","    \"rank_test_score\"]]"],"metadata":{"id":"4j1KqMMXVbK1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mejor métrica obtenida qeuda almacenada en el atributo `best_score_`"],"metadata":{"id":"EKGOcF6CVIqv"}},{"cell_type":"code","source":["print(f\"El accuracy al implementar la estrategia es: {knn_grid_search.best_score_:.2f}\")# métrica en el mejor caso"],"metadata":{"id":"joOrBGm4VQL_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Examinemos los mejores parámetros obtenidos en la búsqueda mirando el atributo `best_params_`"],"metadata":{"id":"5EtqyhPEBCf0"}},{"cell_type":"code","source":["print(f\"El mejor conjunto de hiperparámetros (de los que evaluamos) es: {knn_grid_search.best_params_}\")"],"metadata":{"id":"72pBwWt_AUw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos que en caso de repetirse los resultados óptimos (mean y std) desde la tabla, la estrategia selecciona la primera combinación de hiperparámetros de acuerdo al índice del fold evaluado (n° 62)."],"metadata":{"id":"QOOSopz9cyD1"}},{"cell_type":"markdown","source":["Evaluemos la métrica en el conjunto de test que dejamos aparte:"],"metadata":{"id":"Z933YV5vfybG"}},{"cell_type":"code","source":["accuracy_test = knn_grid_search.score(data_test, target_test)\n","print(f\"Accuracy en el conjunto de test: {accuracy_test:.3f}\")"],"metadata":{"id":"xXhHoYfufyF4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La métrica score, en este caso accuracy, estimada en el conjunto de test que dejamos aparte, es cercana al valor óptimo obtenido para la mejor combinación de hiperparámetros y está dentro del rango de los calculados (ver tabla de arriba). Esto implica que el procedimiento de ajuste no causó un sobre-ajuste mayor. Si quisieramos usar el modelo optimo para realizar predicciones en nuevos datos, podemos hacerlo con el método `.predict()` visto en clases anteriores."],"metadata":{"id":"SYo1VXNjfmEb"}},{"cell_type":"markdown","source":["**¿será correcto asumir el desempeño de generalización del modelo usando la(s) métrica(s) obtenidas a partir del proceso de búsqueda de hiperparámetros anterior?**"],"metadata":{"id":"Aa1lZnvYwy9L"}},{"cell_type":"markdown","source":["La respuesta es **NO**, yaque estamos buscando los hiperparámetros en el mismo dataset usado para estimar las métricas, el resultado podría estar sesgado a esa selección, aún cuando evaluemos su desempeño en un conjunto de test aparte (como en el ejemplo).\n","\n","Lo que haremos, será anidar otro proceso de validación cruzada externo para evaluar la capacidad de generalización del modelo y no sobre-estimar su desempeño a la hora de compararlo con otros modelos. Este proceso se conoce como validación cruzada anidada o *nested cross validation* en inglés. La imagen de más abajo resume este procedimiento:"],"metadata":{"id":"py34u9c19jQc"}},{"cell_type":"markdown","source":["\n","<center><img src=https://hackingmaterials.lbl.gov/automatminer/_images/cv_nested.png width=\"750\" ></center>\n","\n","\n","[fuente](https://hackingmaterials.lbl.gov/automatminer/advanced.html)"],"metadata":{"id":"VEqW61Fh24eq"}},{"cell_type":"markdown","source":["El procedimiento se puede resumir como sigue:\n","\n","1. Crear una estrategia externa de validación cruzada y una interna para ajuste de hiperparámetros.\n","2. En cada fold de entrenamiento externo, encontrar el modelo con hiperparámetros óptimos usando una estrategia como búsqueda exhaustiva con `GridSearchCV` u otra, y estimar luego su desempeño para el conjunto de prueba de ese fold externo. Notar que en el ciclo interno también se realiza un procedimiento de validación cruzada.\n","3. Repetir por cada fold del ciclo externo (outer loop) y estimar las métricas de desempeño de generalización del modelo propuesto.\n","4. Dado que en cada fold de entrenamiento externo podemos obtener diferentes combinaciones de hiperparámetros óptimos, seleccionar la combinación que más se repita. Si no se repiten, repetir la búsqueda de hiperpárametros (con los mismos ajustes del punto 2) pero en todos los datos disponibles, indicando esta vez como métrica final la obtenida a través de validación cruzada anidada."],"metadata":{"id":"xlcpVtPh86lU"}},{"cell_type":"markdown","source":[" Para el ejemplo de más arriba tendremos:"],"metadata":{"id":"CQyzL-dlyb0w"}},{"cell_type":"code","source":["#definimos el algoritmo que evaluaremos\n","model_knn = KNeighborsClassifier()\n","#definimos la rejilla de hiperparámetros que usaremos con el procedimiento de búsqueda\n","PARAM_GRID  = {\"n_neighbors\": range(1, 21),\n","               \"metric\": [\"minkowski\",\"euclidean\",\"manhattan\",\"cosine\"]}\n","#definimos la estrategia de búsqueda\n","search      = GridSearchCV(model_knn,\n","                               param_grid= PARAM_GRID,\n","                               scoring=\"accuracy\",\n","                               cv=10)\n","\n","#definimos la estrategia de validación cruzada\n","CV         = KFold(n_splits = 5, shuffle = True, random_state = 1)\n","# aplicamos la estrategia de validación cruzada anidada, con todos los datos disponibles\n","cv_outer   = cross_validate(search, X, y, cv = CV, scoring='accuracy', return_estimator=True)\n"],"metadata":{"id":"YZqpAhSv-W5B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego, el error de generalización del modelo será:"],"metadata":{"id":"52C8kmmi_z-f"}},{"cell_type":"code","source":["cv_outer = pd.DataFrame(cv_outer)\n","cv_test_scores = cv_outer['test_score']\n","print(\"El desempeño de generalización medido con el score accuracy e implementando ajuste de hiperparámtros es: \\n\"\n","    f\"{cv_test_scores.mean():.3f} ± {cv_test_scores.std():.3f}\")"],"metadata":{"id":"MwStsynT_2ft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El resultado es compatible con lo encontrado previamente, aunque un poco menor, es más correcto indicar esta métrica y su variabilidad como el desempeño del modelo. Ahora queda indicar cuál es la combinación de hiperparámetros óptima con la que entrenaremos el modelo en todos los datos, veamos los modelos ajustados en cada fold externo (para esto siempre usar `return_estimator = True`):"],"metadata":{"id":"PaPsevEfAesv"}},{"cell_type":"code","source":["for cv_fold, estimator_in_fold in enumerate(cv_outer[\"estimator\"]):\n","    print(\n","        f\"Mejores hiperparámetros para el modelo en el fold #{cv_fold + 1}:\\n\"\n","        f\"{estimator_in_fold.best_params_}\"\n","    )"],"metadata":{"id":"xAJHFr9IBVZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sería ideal que la selección de hiperparámetros fuera la misma para todos los folds externos, como no es así, repitamos el procedimiento de búsqueda usando todos los datos y configurando los mismos parámetros de búsqueda anteriores:"],"metadata":{"id":"Fn8mmM5lCoqc"}},{"cell_type":"code","source":["search.fit(X, y)# ajustamos los hiperparámetros usando la estrategia de búsqueda definida anteriormente\n","print(f\"El mejor conjunto de hiperparámetros es: {knn_grid_search.best_params_}\")"],"metadata":{"id":"SUrgbtdFCodB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusión:**\n","\n","Aún cuando llegamos a la misma conclusión respecto a los hiperparámetros buscados con el procedimiento de validación cruzada simple (`metric = 'cosine` y `n_neighbors= 3`), ahora tenemos una medida de desempeño más correcta y con una indicación de variabilidad de la métrica accuracy (0.967 ± 0.024). Aplicar este procedimiento en futuros análisis."],"metadata":{"id":"q3MKg2gAFEUF"}},{"cell_type":"markdown","source":["## 2. Árboles de descisión\n","\n","Los árboles de decisión son uno de los algoritmos de machine learning más conocidos y usados por su facil interpretación, en este ejemplo, trabajaremos con el mismo conjunto de datos anterior y tendremos cuidado en los hiperparámetros ajustados, yaque, al menos con el de `max_depth`, podemos sobre-ajustar rápidamente el modelo. Partamos por implementar el modelo con ajustes de hiperparámetros básicos."],"metadata":{"id":"FtmHlqYbYZJl"}},{"cell_type":"code","source":["# Usemos los datos de clasificación de especies de pingüinos\n","penguins = pd.read_csv(\"https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/datasets/penguins_classification.csv\")\n","\n","# solo usaremos las clases Adelie y Chinstrap\n","FEATURES  = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n","LABELS    = penguins[\"Species\"].unique()\n","data_p    = penguins[FEATURES].values\n","target_p  = penguins[\"Species\"].values\n","\n","# dividamos el conjunto de datos en entrenamiento y test\n","data_train, data_test, target_train, target_test = train_test_split(data_p, target_p, test_size=0.2, random_state=42)"],"metadata":{"id":"lWYfWbT9f4DT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# número de datos por especie\n","penguins[\"Species\"].value_counts()"],"metadata":{"id":"FULahU243wfQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","tree_clf = DecisionTreeClassifier(max_depth=2, criterion = \"gini\", random_state=42)\n","tree_clf.fit(data_train, target_train)"],"metadata":{"id":"EwnGXGdqVzDF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Desempeño del árbol de decisiones entrenado:"],"metadata":{"id":"xQjT5j0pQ3Lc"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","print(f\"El accuracy en test del árbol de desiciones es: {accuracy_score(target_test, tree_clf.predict(data_test))}\\n\")\n","print(f\"El accuracy en train del árbol de desiciones es: {accuracy_score(target_train, tree_clf.predict(data_train))}\")"],"metadata":{"id":"z-8hedvpQ7fv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualicemos el árbol entrenado:"],"metadata":{"id":"0GJi978YYKRI"}},{"cell_type":"code","source":["from sklearn.tree import plot_tree\n","from sklearn.utils.multiclass import unique_labels # para un orden correcto de las etiquetas como la define sklearn\n","\n","plt.figure(figsize = [12,7])\n","plot_tree(tree_clf, feature_names = FEATURES, class_names = unique_labels(target_train, tree_clf.predict(data_train)), filled=True)\n","plt.title(\"Árbol de decisión entrenado sin ajuste de hiperparámetros\")\n","plt.show()"],"metadata":{"id":"53cGCwTuYNjH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En la figura anterior, vemos que para una profundidad 2 del árbol, tenemos una separación de las clases en base a los umbrales de variables estimados en el entrenamiento, en este caso, la métrica gini nos a un indicio de la calidad o impureza de una separación, siendo los valores más pequeños deseables (menor impureza en la separación). La visualización también entrega información de cuántas muestras están siendo clasificadas en cada nodo y por cada clase (lista `value`).   "],"metadata":{"id":"v0yb3SpIdjvb"}},{"cell_type":"markdown","source":["Apliquemos ahora un procedimiento de búsqueda de hiperparámetros para encontrar el óptimo de `max_depth` y de `criterion`"],"metadata":{"id":"9qjNnjYfiQHA"}},{"cell_type":"code","source":["#definimos el algoritmo que evaluaremos\n","model_tree = DecisionTreeClassifier()\n","#definimos la rejilla de hiperparámetros que usaremos con el procedimiento de búsqueda\n","PARAM_GRID  = {\"max_depth\": [1, 3, 5, 7, 9, 11],#profundidad del árbol, qué significa el caso None?\n","               \"criterion\": [\"gini\",\"entropy\"],# criterio de impureza para la división de un nodo\n","               \"min_samples_leaf\": range(1, 11,2),# el mínimo número de muestras para estar en un nodo\n","               \"max_leaf_nodes\":range(2, 20,2),#los mejores nodos se definen en relación a la reducción relativa de impureza\n","               \"min_samples_split\":range(2, 11,2)#el número mínimo de muestras requeridas para dividir un nodo interno\n","               }\n","#definimos la estrategia de búsqueda\n","search_tree = GridSearchCV(model_tree,\n","                           param_grid= PARAM_GRID,\n","                           scoring=\"accuracy\",\n","                           cv=10)\n","search_tree.fit(data_p, target_p)# ajustamos los hiperparámetros usando la estrategia de búsqueda definida anteriormente\n","print(f\"El mejor conjunto de hiperparámetros es: {search_tree.best_params_}\\n\")\n","print(f\"El accuracy al implementar la estrategia es: {search_tree.best_score_:.2f}\")# métrica en el mejor caso"],"metadata":{"id":"F9gKHLb1iZMw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entrenemos el modelo en todos los datos con los mejores hiperparámetros encontrados:"],"metadata":{"id":"uLmOesphuPvA"}},{"cell_type":"code","source":["tree_final = DecisionTreeClassifier(max_depth         = search_tree.best_params_['max_depth'],\n","                                    criterion         = search_tree.best_params_['criterion'],\n","                                    min_samples_leaf  = search_tree.best_params_['min_samples_leaf'],\n","                                    max_leaf_nodes    = search_tree.best_params_['max_leaf_nodes'],\n","                                    min_samples_split = search_tree.best_params_['min_samples_split'],\n","                                    random_state=42)\n","tree_final.fit(data_p,target_p)"],"metadata":{"id":"KwlNEXKeuPfH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualicemos el árbol para esta configuración encontrada de hiperparámetros óptimos:"],"metadata":{"id":"zW9OTK6fpFOR"}},{"cell_type":"code","source":["from sklearn.tree import plot_tree\n","\n","plt.figure(figsize = [16,12])\n","plot_tree(tree_final,  feature_names = FEATURES, class_names = unique_labels(target_p, tree_clf.predict(data_p)), filled=True)\n","plt.title(\"Árbol de decisión entrenado en todos los datos y con hiperparámetros ajustados\")\n","plt.show()"],"metadata":{"id":"uYKN7NNNpD2t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El modelo también nos entrega un atributo para evaluar la importancia de las variables predictoras:"],"metadata":{"id":"8IMXVS7qq-ii"}},{"cell_type":"code","source":["def plot_feature_importances_tree(model,n_features, feature_names):\n","    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n","    plt.yticks(np.arange(n_features), feature_names)\n","    plt.xlabel(\"Importancia de las variables\")\n","    plt.ylabel(\"Variable\")\n","    plt.ylim(-1, n_features)\n","\n","plot_feature_importances_tree(tree_final,data_p.shape[1],FEATURES)"],"metadata":{"id":"wMC5ZnTarH8z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Nota:** solo para efectos de no hacer tan largo del notebook, se omiten algunos pasos vistos anteriormente, cómo estimación de métricas de desempeño, visualizaciones, etc."],"metadata":{"id":"uF30-Ajkn6tf"}},{"cell_type":"markdown","source":["Queda como tarea evaluar el modelo desde el punto de vista de la generalización (usando *nested cross validation*)   "],"metadata":{"id":"ThPGgnyjuaQH"}},{"cell_type":"markdown","source":["**Existirá una forma extra de simplificar el árbol encontrado?**\n","\n","**SI**, y se conoce como poda (*prunning*), esto recorta o descarta algunas ramas de decisión del árbol antes (*pre-prunning*) o después (*post-prunning*) del entrenamiento, la primera estrategia consiste en definir los hiperparámetros mediante un proceso de búsqueda, como lo hicimos más arriba,la segunda, en analizar el árbol en base a un criterio de complejidad (cost complexity parameter `ccp_alpha` en scikit learn), veamos un ejemplo:"],"metadata":{"id":"H60jB9QpU4OL"}},{"cell_type":"code","source":["clf_alpha = DecisionTreeClassifier(random_state=42)\n","path = clf_alpha.cost_complexity_pruning_path(data_train, target_train)\n","ccp_alphas, impurities = path.ccp_alphas, path.impurities\n","print(ccp_alphas)"],"metadata":{"id":"tbWLtoygVHzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La estrategia de post-poda consistirá en encontrar el parámetro correcto de alpha, analicemos la exactitud par el conjunto de train y test que definimos:"],"metadata":{"id":"f2BDGkQXnVLB"}},{"cell_type":"code","source":["#Entrenemos modelos para diferentes valores de alpha, fijemos los hiperparámetros encontrados antes\n","clfs = []\n","ccp_alphas = list(ccp_alphas[0:len(ccp_alphas)-3])\n","for ccp_alpha in ccp_alphas:\n","    clf = DecisionTreeClassifier(random_state=42,\n","                                 ccp_alpha=ccp_alpha)\n","    clf.fit(data_train, target_train)\n","    clfs.append(clf)\n","\n","#Gráfico de accuracy en train y test\n","train_scores = [clf.score(data_train, target_train) for clf in clfs]\n","test_scores = [clf.score(data_test, target_test) for clf in clfs]\n","\n","fig, ax = plt.subplots()\n","ax.set_xlabel(\"alpha\")\n","ax.set_ylabel(\"accuracy\")\n","ax.set_title(\"Accuracy vs alpha para conjuntos de train y test\")\n","ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n","ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n","ax.legend()\n","plt.show()"],"metadata":{"id":"PDPT5n0enwrx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego, podemos escoger alpha = 0.01 para entrenar el modelo final y tener una pequeña evaluación de su desempeño, tenemos entonces:"],"metadata":{"id":"qeJTlS_GqqGM"}},{"cell_type":"code","source":["clf_final = DecisionTreeClassifier(random_state=42,\n","                                   ccp_alpha=0.01)\n","clf_final.fit(data_p, target_p)\n","\n","#árbol con post-poda\n","plt.figure(figsize = [14,10])\n","plot_tree(clf_final, feature_names = FEATURES, class_names = unique_labels(target_p, tree_clf.predict(data_p)), filled=True)\n","plt.title(\"Árbol de decisión entrenado con post-poda en todos los datos\")\n","plt.show()"],"metadata":{"id":"VUwc_JNjq1ID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Desempeño árbol con post-poda\n","CV         = KFold(n_splits = 10, shuffle = True, random_state = 1)# definimos el tipo de estrategia de validación cruzada, KFold en este caso con 10 folds y con reordanmiento aleatorio de los datos originales\n","cv_results = cross_validate(DecisionTreeClassifier(random_state=42, ccp_alpha=0.01), data_p, target_p, cv = CV, scoring='accuracy')# aplicamos la estrategia\n","\n","# Resultados\n","print(f\"El promedio del accuracy (y su desviación estándar) en los conjuntos de prueba de validación cruzada, con árbol de decisión con post poda es: \"\n","      f\"{cv_results['test_score'].mean():.2f} ({cv_results['test_score'].std():.2f})\")"],"metadata":{"id":"DdBo-i9-rN52"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Así mismo podemos usar también los hiperparámetros ajustados anteriormente antes de la post-poda, cómo cambiará el árbol? **experimentar**."],"metadata":{"id":"dgvKRC_8tNND"}},{"cell_type":"markdown","source":["Matriz de confusión en todos los datos:"],"metadata":{"id":"w6o-V8dUu0DS"}},{"cell_type":"code","source":["from sklearn.utils.multiclass import unique_labels\n","\n","target_pred = clf_final.predict(data_p)\n","UNIQUE_LABELS = unique_labels(target_p, target_pred)# importante!: para obtener las clases en el orden que define sklearn\n","cm = confusion_matrix(target_p,target_pred,labels = UNIQUE_LABELS)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=UNIQUE_LABELS)\n","disp.plot()\n","plt.title(\"Matriz de confusión en datos disponibles\")\n","plt.show()"],"metadata":{"id":"HaLfwkDKu5dy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Por último, podemos estimar la probabilidad con que se predice la clase de una muestra de datos:"],"metadata":{"id":"f20HxMrt6WpV"}},{"cell_type":"code","source":["sample          = data_p[0:1,:]# ejemplificamos con una muestra tomada desde el dataset original\n","y_pred_proba    = clf_final.predict_proba(sample)\n","y_proba_class_0 = pd.Series(y_pred_proba[0], index=clf_final.classes_)\n","print(f\"Probabilidades de la muestra {sample} de pertenecer a una clase:\\n{y_proba_class_0}\")\n","y_proba_class_0.plot.bar()\n","plt.ylabel(\"Probabilidad\")\n","_ = plt.title(\"Probabilidad de pertenecer a la clase de un pungüino\")"],"metadata":{"id":"FqYtMP216feW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Ejercicios extra"],"metadata":{"id":"YNz94jrfVW3M"}},{"cell_type":"markdown","source":["**1.** En el ejemplo de árboles de decisión (ejemplo usando ajuste de hiperparámetros), usar validación cruzada anidada para entregar una estimación de la capacidad de generalización del modelo en base a una métrica de desempeño definida."],"metadata":{"id":"O0lRI3WAVbdC"}},{"cell_type":"markdown","source":["**2.** Implementar un ejemplo para el conjunto de datos de especies de pingüinos comparando el desempeño de los modelos de: i) regresión logística, ii) k-vecinos más cercanos, iii) árboles de decisión y iv) máquinas de soporte vectorial.\n","- Implementar validación cruzada anidada con búsqueda de al menos un hiperparámetro por modelo en el reporte de sus resultados.\n","- ¿qué modelo seleccionaría para estos datos en base a este análisis?\n","\n","- Mostrar la matriz de confusión para el modelo seleccionado y evaluado en todos los datos."],"metadata":{"id":"mCSHnZDwXNzn"}},{"cell_type":"markdown","source":["**4.** Nombre las ventajas y desventajas del algoritmo de árboles de decisión."],"metadata":{"id":"shlOo14ql3ZT"}},{"cell_type":"markdown","source":["**5.** Investigue para qué algoritmos de clasificación es relevante la estandarización o escalado de las variables predictoras previo al entrenamiento y programe un ejemplo donde se aprecie el efecto de realizar o no este pre-procesamiento."],"metadata":{"id":"WD0kcq5nmBWY"}},{"cell_type":"markdown","source":["**6.** Reproducir el ejemplo mostrado en la documentación de scikit learn para clasificación de dígitos escritos a mano: [descrito aquí](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html), pero incluyendo una estrategia de validación cruzada anidada y procedimiento de búsqueda para selección de al menos dos hiperparámetros del algoritmo."],"metadata":{"id":"wZDzDKC_Myji"}},{"cell_type":"markdown","source":["## Referencias"],"metadata":{"id":"1R4Nn4XBOZha"}},{"cell_type":"markdown","source":["**1.** Algunos de los contenidos fueron adaptados del curso \"Machine Learning in Python with scikit-learn\" de INRIA (National Institute for Research in Digital Science and Technology, Francia), lo pueden tomar gratuitamente acá: https://www.fun-mooc.fr/en/courses/machine-learning-python-scikit-learn/\n","\n","**2.** Para profundizar en la búsqueda de hiperparámetros: [enlace1](https://www.youtube.com/watch?v=YAfS8-BXp8Q), [enlace2](https://www.youtube.com/watch?v=WHcEg4HXsH4), [enlace3](https://www.youtube.com/watch?v=tIO8zPCdi58).\n","\n","**3.** Algoritmo K-Vecinos mas Cercanos: [enlace](https://python-course.eu/machine-learning/k-nearest-neighbor-classifier-with-sklearn.php)\n","\n","**4.** Algoritmo de máquinas de soporte vectorial, importancia del estandarizado de los datos: [enlace](https://winder.ai/support-vector-machines/).\n","**5.** Algoritmo de máquina de soporte vectoria, ejemplo clasificación de imágenes de rostros: [enlace](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb#scrollTo=JO0LrAJlIMEH).\n","\n","**6.** Algoritmo de máquina de soporte vectorial con ajuste de hiperparámetros: [enlace](https://www.youtube.com/watch?v=b4qQzVPWkZQ).\n","\n","**7.** Bosques aleatorios: [enlace](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.08-Random-Forests.ipynb#scrollTo=yKndK0APLLj3).\n",""],"metadata":{"id":"cbShiR4UOb06"}}]}