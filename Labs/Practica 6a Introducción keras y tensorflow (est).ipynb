{"cells":[{"cell_type":"markdown","metadata":{"id":"DV45IZ9474vp"},"source":["#**Práctica 6a: Leyendo algunos tipos de datos e introducción Keras y Tensorflow**\n","\n","Curso: Inteligencia Artificial para Ingenieros\n","\n","Prof. Carlos Toro N. (carlos.toro.ing@gmail.com)\n","\n","2022"]},{"cell_type":"markdown","metadata":{"id":"gcYaBcWu8NH4"},"source":["**Introducción**"]},{"cell_type":"markdown","metadata":{"id":"MYwBZnFIDoQt"},"source":["En esta práctica leeremos algunos tipos de datos típicos con los que podemos trabajar (no usaremos texto ya que tiene muchos más desafíos) e introduciremos algunos de los conceptos básicos Tensorflow y Keras."]},{"cell_type":"markdown","metadata":{"id":"lMJMHb-BsmHM"},"source":["**PREVIO:** Importaciones necesarios para la práctica"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","import tensorflow_datasets as tfds\n","\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL # Pillow es otra librería para temas de procesamiento de imágenes\n","import PIL.Image"],"metadata":{"id":"AnMcX8N8146v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Antes de ejecutar las siguientes celdas, subir las imágenes y audio entregados (u otros propios)"],"metadata":{"id":"s5qxVDiOF7Vz"}},{"cell_type":"code","source":["# versión actual de tensorflow\n","print(tf.__version__)"],"metadata":{"id":"NXzxzgtWlXKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Is952HwcNu_K"},"source":["## **1. Leyendo otros tipos de datos**"]},{"cell_type":"markdown","source":["###**1.1 Imágenes**"],"metadata":{"id":"XRPGEsGdGM30"}},{"cell_type":"code","source":["img_names = tf.data.Dataset.list_files('*.jpg')# útil para crear/leer un dataset en base a la extensión de archivos indicado"],"metadata":{"id":"y8cI-tMlGcwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im = []\n","N  =len(img_names)\n","for i,image in enumerate(img_names):\n","    raw = tf.io.read_file(image)#qué tipo de variable será raw?\n","    im.append(tf.image.decode_jpeg(raw))\n","    plt.subplot(1,N,i+1)\n","    plt.imshow(im[i])\n","    plt.show\n","\n","# tipo de dato de las imágenes\n","print(f\"Las imágenes son de tipo: {type(im[0])}\")"],"metadata":{"id":"N1gZKFqZGaQf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Algunas operaciones osbre las imágenes"],"metadata":{"id":"gvDrb0z2HgJQ"}},{"cell_type":"code","source":["plt.figure()\n","plt.subplot(1,2,1)\n","plt.title('Ajuste de brillo')\n","plt.imshow(tf.image.adjust_brightness(im[1],delta = 0.3))#ajuste del brillo, el parámetro toma valores entre  0 y 1, 1 para blanco\n","\n","plt.subplot(1,2,2)\n","plt.title('Refleja imagen horizontalmente')\n","plt.imshow(tf.image.flip_left_right(im[1]))#refleja horizontalmente la imagen\n","plt.show()"],"metadata":{"id":"aZBf3h-oHJOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**1.2 Audio**"],"metadata":{"id":"xcS2IfVYIAeI"}},{"cell_type":"markdown","source":["Uasremos en este caso la libreria ``librosa`` de python, dedicada para trabajar con música y audio."],"metadata":{"id":"-CKzAvkLIR3l"}},{"cell_type":"code","source":["#Algunos imports necesarios\n","import librosa\n","import librosa.display as dsp\n","from IPython.display import Audio\n","import matplotlib.pyplot as plt"],"metadata":{"id":"zrNSD3bCIUYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cargaremos un par de audios disponibles en la librería, uno de sonido monocanal, y uno stereo."],"metadata":{"id":"-gJafdaVIZF9"}},{"cell_type":"code","source":["# archivo mono canal\n","audio1, Fs1 = librosa.load(librosa.util.example_audio_file(),duration = 60)\n","Audio(data = audio1, rate = Fs1)"],"metadata":{"id":"rsiD5vK_IamV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Información del audio:"],"metadata":{"id":"nnPj5PrjIeCx"}},{"cell_type":"code","source":["print('Forma de los datos',audio1.shape)# tenemos una dimension de dos columnas, porque el audio es de dos canales\n","print('Frecuencia de muestreo: ',Fs1,'Hz')\n","print('Número de muestras totales: ', audio1.shape)"],"metadata":{"id":"pUIOcdanIg5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# archivo de audio stereo\n","audio2, Fs2 = librosa.load(librosa.util.example_audio_file(),mono = False,duration = 60)\n","Audio(data = audio2, rate = Fs2)"],"metadata":{"id":"fAtIjx1rIkFk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Información del audio:"],"metadata":{"id":"VyZxnNYWIpe9"}},{"cell_type":"code","source":["print('Forma de los datos',audio2.shape)# tenemos una dimension de dos filas, porque el audio es de dos canales ahora\n","print('Frecuencia de muestreo: ',Fs2,'Hz')\n","print('Número de muestras totales: ', audio2.shape[1])"],"metadata":{"id":"NuhksGUvIpFj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este caso analicemos el audio mono canal:"],"metadata":{"id":"4PRHf7gPIwPZ"}},{"cell_type":"code","source":["plt.figure(figsize = (10,3))\n","librosa.display.waveshow(audio1, sr=Fs1)\n","plt.title('Audio Mono')\n","plt.ylabel('Amplitud')\n","plt.xlabel('Tiempo')\n","plt.show()"],"metadata":{"id":"pX9EiRjaIxtn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Representación de la señal en tiempo-frecuencia con la STFT,\n","utilizamos la función de ``stft()`` de la libreria, la documentación la pueden encontrar [acá](http://librosa.org/doc/main/generated/librosa.stft.html)."],"metadata":{"id":"2VMmEVB7Iz5M"}},{"cell_type":"code","source":["d = librosa.stft(audio1)# calcula la Transformada de Fourier de Tiempo Corto (Short-Time Fourier Transform)\n","D = librosa.amplitude_to_db(np.abs(d),ref=np.max)# pasamos a db\n","\n","plt.figure(figsize = (10,3))\n","dsp.specshow(D, y_axis='linear', x_axis='s',sr=Fs1)\n","plt.show()"],"metadata":{"id":"yYc02g8cI1-A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2. Dataset Augmentation**"],"metadata":{"id":"quAMe30_JRFr"}},{"cell_type":"markdown","source":["En este ejemplo usaremos el módulo ``tfds`` entrega un conjunto de datasets para usar con tensorflow y otros frameworks de Machine Learning.\n","\n","El ejemplo siguiente fue tomado desde [documentación oficial tensorflow](https://www.tensorflow.org/tutorials/images/data_augmentation)"],"metadata":{"id":"Q1GGhpCnJc2L"}},{"cell_type":"code","source":["# Descargamos un dataset\n","(train_ds, val_ds, test_ds), info = tfds.load(\n","                                                'tf_flowers',\n","                                                split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n","                                                with_info=True,\n","                                                as_supervised=True,\n","                                              )"],"metadata":{"id":"fXMn4oOKJcl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# este dataset contiene 5 clases\n","print('Número de clases: ',info.features['label'].num_classes)\n","print('Nombre de clases: ',info.features['label'].names)\n","print('Número total de imágenes de entrenamiento: ',info.splits['train'].num_examples)"],"metadata":{"id":"1cIldI6hJl2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mostramos algunas imagenes disponibles\n","get_label_name = info.features['label'].int2str\n","data_iter    = iter(train_ds)# iter genera un iterador sobre el objeto que hace referencia al dataset\n","\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","  image, label = next(data_iter)#next va accediendo a los elementos de este iterable\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(image)\n","  plt.title(get_label_name(label))\n","  plt.axis('off')"],"metadata":{"id":"wy4ZLmIvJ2Co"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usamos keras para realizar algunas transformaciones sobre las imágenes"],"metadata":{"id":"09sWnYuPJ50P"}},{"cell_type":"code","source":["IMG_SIZE = 180\n","image, label    = next(iter(train_ds))\n","resize_and_rescale = keras.Sequential([\n","                                          layers.Resizing(IMG_SIZE, IMG_SIZE),\n","                                          layers.Rescaling(1./255)\n","                                         ])\n","\n","result = resize_and_rescale(image)\n","plt.imshow(result)\n","plt.show()\n","\n","# nueva escala de los valores de los pixeles\n","print(\"Min and max pixel values:\", result.numpy().min(), result.numpy().max())"],"metadata":{"id":"Zh5TX2ezJ7no"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aumentación del dataset completo:"],"metadata":{"id":"V2cyo9RhKyX8"}},{"cell_type":"code","source":["#definimos las transformaciones\n","data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal_and_vertical\"),\n","                                      layers.RandomRotation(0.2)])"],"metadata":{"id":"TW4bJifyKxuD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ejecutamos algunas iteraciones para llamar a data_augmentation()\n","# cada vez que se llame ejecutará una de las operaciones de forma aleatoria\n","image, label    = next(iter(train_ds))# cargamos una imagen\n","# Añadimos una dimensión a la imagen a transformar para usar el método definido\n","image = tf.expand_dims(image, 0)\n","\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","  augmented_image = data_augmentation(image)\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(augmented_image[0].numpy().astype('uint8'))\n","  plt.axis(\"off\")\n","plt.show()"],"metadata":{"id":"NsFdMXNcK8tF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ejemplo tomado desde acá: https://www.tensorflow.org/tutorials/images/data_augmentation"],"metadata":{"id":"TJPHfpHiMoxO"}},{"cell_type":"markdown","source":["##**3. Módulos comúnes de Tensorflow**"],"metadata":{"id":"a76FLFEMpGd-"}},{"cell_type":"markdown","source":["Tanto en los modelos de machine learning que hemos visto como los de deep learning, tenemos un ciclo de vida de los modelos, en particular, veremos como se implementa usando la API de alto nivel de Tensorflow: Keras,"],"metadata":{"id":"7fAamJWhyPxK"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers"],"metadata":{"id":"xX9VXVb1pZIt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dos formas de construir modelos:\n","con el enfoque secuencial/apilado o el método funcional."],"metadata":{"id":"r9tKupygpeut"}},{"cell_type":"code","source":["modelo_apilado = tf.keras.Sequential()#modelo apilado, la forma más común de construir modelos\n","\n","modelo_apilado.add(layers.Dense(32,activation = 'relu'))#Dense hace referencia a una capa fully connected\n","modelo_apilado.add(layers.Dense(32,activation = 'relu'))\n","modelo_apilado.add(layers.Dense(32,activation = 'relu'))\n","modelo_apilado.add(layers.Dense(10,activation = 'softmax'))\n",""],"metadata":{"id":"70_3xaPzpeNV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usando modelos funcionales con `tf.keras.Input` y `tf.keras.Model` Construir modelos de esta forma es más compleja pero a su vez es más versatil\n","permite pasar variables y datos entre diferentes fases de procesamiento. Estos se prefieren en casos donde se requiere más de una salida."],"metadata":{"id":"hcUYVZWYp039"}},{"cell_type":"code","source":["x  = tf.keras.Input(shape=(32,))\n","h1 = layers.Dense(32,activation='relu')(x)\n","h2 = layers.Dense(32,activation ='relu')(h1)\n","y  = layers.Dense(10,activation='softmax')(h2)\n","\n","modelo_funcional = tf.keras.models.Model(x,y)\n","modelo_funcional.summary()"],"metadata":{"id":"ZCQ6rEHgqASW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Capas que podemos utilizar con tf.keras.layers**\n","\n","* tf.keras.layers.Dense: Crea capas completamente conectadas\n","* tf.keras.layers.Conv2D: crea una capa conv. bidimensional\n","* tf.keras.MaxPooling2D\n","* tf.keras.AveragePooling2D\n","* tf.keras.layers.RNN\n","* tf.keras.layers.LSTM\n","* tf.keras.layers.GRU\n","* tf.keras.Dropout"],"metadata":{"id":"kmi-kRfYqNWG"}},{"cell_type":"code","source":["help(tf.keras.layers.Dense)"],"metadata":{"id":"IcFPfK01qLel"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dos formas de definir la función de activación en una capa\n","layers.Dense(32, activation = 'sigmoid')\n","layers.Dense(32, activation = tf.sigmoid)"],"metadata":{"id":"ITC3VnERqe39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Regularización\n","layers.Dense(32,kernel_regularizer=tf.keras.regularizers.l2())"],"metadata":{"id":"1GII9Eb8qh0F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Entrenamiento y Evaluación**"],"metadata":{"id":"NOp2OS7Fqsbc"}},{"cell_type":"markdown","source":["Luego de que los modelos son definidos, compile() se llama para configurar el proceso de entrenamiento del modelo.\n","\n","Aquí podemos definir términos como:\n","\n","* tipo de optimizador: ej. rmsprop (default), adam, ...\n","* loss function: ej. cross entropy para tareas de clasificación, MSE para tareas de regresión.\n","* metrics: ej. accuracy\n","* loss_weights"],"metadata":{"id":"GMEcNNd1qxFd"}},{"cell_type":"code","source":["model2 = tf.keras.Sequential()#definimos un modelo secuencial\n","help(model2.compile)"],"metadata":{"id":"BqQZb3WTqywN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# por ejemplo:\n","model2.add(layers.Dense(10,activation='softmax'))\n","model2.compile(optimizer='Adam',loss=tf.keras.losses.categorical_crossentropy,metrics=[tf.keras.metrics.categorical_accuracy])"],"metadata":{"id":"qePadvctq2cN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego, para entrenar el modelo podemos ocupar el método fit, este recibe como argumentos, entre otros:\n","\n","* los datos de entrenamiento\n","* el número de epocas que se entrenará el modelo, recordar, cada época representa una pasada completa del set de datos por la red.\n","* el tamaño del batch que estará viendo la red antes de actualizar los pesos,\n","* también se pueden incluir datos de validación para aplicar estrategias como detención temprana (early stopping)"],"metadata":{"id":"92qWs19Aq_y9"}},{"cell_type":"code","source":["# simulemos algunos datos y entrenemos el modelo definido\n","import numpy as np\n","\n","train_x = np.random.random((1000,36))\n","train_y = np.random.random((1000,10))\n","\n","val_x = np.random.random((200,36))\n","val_y = np.random.random((200,10))\n","\n","\n","model2.fit(train_x,train_y,epochs=10,batch_size=100,validation_data=(val_x,val_y))"],"metadata":{"id":"PTyHX1gDrCdN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Funciones de Callback**\n","Estas será útiles para configurar otras  propiedades del entrenamiento, por ejemplo:\n","\n","* guardar periódicamente los modelos\n","* cambiar dinámicamente la tasa de aprendizaje\n","* configurar la estrategia de early stopping\n","* usar TensorBoard para visualizar el proceso de entrenamiento"],"metadata":{"id":"UfByt3bDrcS9"}},{"cell_type":"code","source":["import os\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","\n","logdir=os.path.join(\"logs\")# para guardar el registro del entrenamiento y visualizarlo luego con TensorBoard\n","if not os.path.exists(logdir):\n","    os.mkdir(logdir)\n","\n","#Número de epocas\n","Epochs = 10\n","\n","# diseñamos una estrategia para cambiar dinámicamente la tasa de aprendizaje durante el entrenamiento\n","# ojo, que algunos optimizadores ya lo hacen, pero esto es mas personalizado\n","def lr_Scheduler(epoch):\n","    if epoch > 0.9*Epochs:\n","        lr=0.0001\n","    elif epoch > 0.5*Epochs:\n","        lr = 0.001\n","    elif epoch > 0.25*Epochs:\n","        lr=0.01\n","    else:\n","        lr=0.1\n","\n","    print(lr)\n","    return lr\n","\n","\n","callbacks = [\n","    #Early stopping:\n","    tf.keras.callbacks.EarlyStopping(\n","        #Métrica para deterinar si el modelo aún se puede mejorar más o no\n","        monitor='val_loss',\n","        #cantidad de cambio minima sobre la metrica usada para evaluar si hubo cambio en el desempeño del modelo\n","        min_delta=1e-2,\n","        # Número de épocas en las cuales el desempeño del modelo no ha mejorado su desempeño\n","        patience=2),\n","    #Guardamos periódicamente el modelo:\n","    tf.keras.callbacks.ModelCheckpoint(\n","        #filepath y nombre del modelo a guardar\n","        filepath='testmodel.h5',\n","        #en caso de querer guardar solo el mejor modelo\n","        save_best_only=True,\n","        #Métrica a monitorear\n","        monitor='val_loss'),\n","    #Cambio dinámico en la tasa de aprendizaje con el scheduler definido por nosotros.\n","    tf.keras.callbacks.LearningRateScheduler(lr_Scheduler),\n","    #Uso de TensorBoard.\n","    tf.keras.callbacks.TensorBoard(log_dir=logdir)\n","]\n"],"metadata":{"id":"JZ0fXE2mrf1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.fit(train_x,train_y,batch_size=15, epochs=Epochs,callbacks=callbacks,validation_data=(val_x,val_y))"],"metadata":{"id":"an3hoKcfriyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# desplegamos resultados en dashboard TensorBoard, opcional. Más detalles en: https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/get_started.ipynb#scrollTo=6B95Hb6YVgPZ\n","%tensorboard --logdir logs/train"],"metadata":{"id":"k2OfhFNZrlrF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Evaluación y predicción usando el modelo entrenado**\n","\n","Usaremos en este caso los métodos:\n","* `.evaluate()`: predice la salida para una determinada entrada y luego calcula la(s) métrica(s) especificadas en .compile() y basado en los valores y_true e y_pred retorna la métrica como valor de salida.\n","* `.predict()`: solo retorna y_pred\n","\n","respectivamente"],"metadata":{"id":"PonF4aJfr3e2"}},{"cell_type":"code","source":["test_x = np.random.random((1000,36))\n","test_y = np.random.random((1000,10))\n","\n","print('Evaluación en datos de prueba:\\n')\n","results = model2.evaluate(test_x,test_y)\n","print(\"Test loss, test acc: \", results)\n","\n","# predicciones en datos\n","print('\\nGeneramos predicciones para 3 muestras:\\n')\n","prediccion = model2.predict(test_x[:4])\n","print(\"Forma de la predicción: \", prediccion.shape)"],"metadata":{"id":"1PB006H-r3S-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Guardar y cargar el modelo entrenado**\n","\n","Podemos usar los métodos:\n","* TensorFlow SavedModel format: recomendado\n","* Keras H5 format: más antiguo con menos información\n","\n","mas información acerca de las formas de guardar modelos [acá](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)"],"metadata":{"id":"1YPXcN1YsEl1"}},{"cell_type":"code","source":["from tensorflow import keras\n","# llamando a `save('my_model')` crea un directorio `my_model` donde se guarda el modelo\n","model2.save(\"my_model\")# por defecto guarda en formato tf, si escriben my_model.h5, guardarán en foromato .h5\n","\n","# Puede ser usado para reconstruir el modelo igualmente\n","reconstructed_model = keras.models.load_model(\"my_model\")"],"metadata":{"id":"ratIA6M9scOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predicciones en datos usando el modelo cargado\n","print('\\nGeneramos predicciones para 1 muestra:\\n')\n","prediccion = reconstructed_model.predict(test_x[[100],:])# muestra 100\n","print(prediccion)\n","print(\"suma de las probabilidades obtenidas:\", prediccion.sum())"],"metadata":{"id":"Fu3i6dewsftF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Otra información que podemos acceder desde los modelos entrenados**"],"metadata":{"id":"ygR2wseWsjZF"}},{"cell_type":"markdown","source":["1. Acceder a los valores de los pesos dentro de cada capa de la red neuronal, usemos para esto el modelo entrenado en la sección anterior, el cual consistía de un modelo de red completamento conectado, con una sola capa:  `model2.add(layers.Dense(10,activation='softmax'))`"],"metadata":{"id":"WcFJ9Ib1snRe"}},{"cell_type":"code","source":["#Inspeccionemos el modelo\n","model2.summary()"],"metadata":{"id":"6lNyGS9ysqAN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Son 370 parámetros que debieramos haber entrenado."],"metadata":{"id":"ZerVpSKBssUG"}},{"cell_type":"code","source":["for layerNum, layer in enumerate(model2.layers):\n","    weights = layer.get_weights()[0]\n","    biases = layer.get_weights()[1]\n","    print(np.shape(weights))\n","    print(np.shape(biases))"],"metadata":{"id":"GAdeE9Tqst6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Pesos de la primera neurona:\\n',weights[:,0])\n","print('Bias de la primera neurona: ',biases[0])"],"metadata":{"id":"M8g9a56rsz02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ejercicios:**\n","\n","1. Existen otras transformaciones que se pueden incluir, entre estas: layers.RandomContrast, layers.RandomCrop,layers.RandomZoom, implementarlas en el set de datos anterior y graficar algunos ejemplos.\n","\n","2. Explorar otros datasets disponibles en Tensorflow\n","\n","3. ¿Qué argumentos en las definiciones de las capas, metodos para configurar el entrenamiento y método para realizar el entrenamiento vistos son obligatorios y cuales son opcionales?, de los opcionales, ¿qué valores por defecto asumen?\n","\n","4. Desafío: Con lo que ya hemos visto, implementar una red neuronal de una capa oculta para un problema de regresión o clasificación vistos en clases anteriores. Tenga cuidado con las dimensiones y definción de capa salida."],"metadata":{"id":"DKqd_QlpMvTx"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOksr2jpiiNTRIrI0nrdUm6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}