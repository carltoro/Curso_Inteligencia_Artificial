{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0kEP93y0kifzf695IEym6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#**Práctica 3: Problemas de Regresión**\n","\n","Curso: Inteligencia Artificial para Ingenieros\n","\n","Prof. Carlos Toro N. (carlos.toro.ing@gmail.com)\n","\n","2022"],"metadata":{"id":"PiIein2liF7l"}},{"cell_type":"markdown","source":["**Introducción**\n","\n","El **análisis de regresión** trata de explicar las relaciones entre variables, es uno de los problemas que pueden resolver las técnicas de machine learning. Consiste en encontrar una función $f$ tal que:"],"metadata":{"id":"l6kruw64jboI"}},{"cell_type":"markdown","source":["$$\n","\\begin{align}y = f(x,\\theta), f: R^n\\rightarrow R^m\\end{align}\n","$$"],"metadata":{"id":"8dDlRU4GrJY2"}},{"cell_type":"markdown","source":["$y$ es la variable objetivo de tipo continua, en el caso más típico es un escalar ($m=1$) pero también puede ser más de una variable de respuesta (un vector), $x$ es la variable predictora o de características y $\\theta$ son los parámetros a optimizar mediante el proceso de entrenamiento.\n","\n","La función $f$ puede ser tan simple como una linea recta o algo tan complejo como una red neuronal artificial, la elección dependerá de la complejidad del problema.\n","\n","Notar que algunas de las técnicas tradicionales como la regresión lineal simple y lineal multivariada han sido históricamente desarrolladas por la estadística, asique es una buena forma de profundizar el tema buscando referencias en esa área.\n"],"metadata":{"id":"PE1c5Zd_rQdu"}},{"cell_type":"markdown","source":["**En esta práctica veremos:**\n","\n","1. Regresión lineal simple\n","2. Regresión polinomial\n","3. Regresión lineal multivariada\n","4. Ajuste de curvas con funciones no lineales\n","5. Ejercicios"],"metadata":{"id":"rZuvMfA4k8nE"}},{"cell_type":"markdown","source":["En esta práctica usaremos herramientas como Sci-kit learn y Scipy para estudiar este tipo de problemas."],"metadata":{"id":"beAdo_rOtJJx"}},{"cell_type":"markdown","source":["##1. Regresión lineal simple"],"metadata":{"id":"vunfPe7hsMW3"}},{"cell_type":"markdown","source":["En la regresión lineal asumimos que la variable dependiente puede ser, aproximadamente, expresada como una combinación lineal de las variables predictoras o características (features). En el caso más simple, una variable predictora, ajustaremos una linea recta a los dadtos. El modleo en este caso tiene la siguiente forma:\n","$$y = ax+b$$\n","aquí $a$ es conocida como la *pendiente*, y $b$ como el *intercepto*."],"metadata":{"id":"ZmeULq5yulcn"}},{"cell_type":"markdown","source":["Primero importemos las librerías importantes para el desarrollo de la práctica:"],"metadata":{"id":"N_4fU3t1vhm7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnKErCX_81Vb"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import sklearn"]},{"cell_type":"markdown","source":["###Ejemplo 1. Regresión lineal simple con datos simulados"],"metadata":{"id":"CMu7mB8G21l_"}},{"cell_type":"markdown","source":["Consideremos los siguientes datos simulados con la relación $y = 2x -5$:"],"metadata":{"id":"dkMYu94GwYnm"}},{"cell_type":"code","source":["# simulamos algunos datos con tendencia lineal y con algo de ruido gaussiano\n","np.random.seed(10)# para asegurar reproducibilidad\n","Np  = 20 # número de puntos a simular\n","x   = np.linspace(0,10,Np)\n","x   = x[:,np.newaxis]# para agregar una dimensión a los datos, los modelos de sklearn requieren datos en la forma [n_samples,n_features]\n","y   = 2 * x - 5 + 2*np.random.randn(Np,1)# desviación estándar 2 del ruido"],"metadata":{"id":"4kQdFd9jwln5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# comprobemos las dimensiones de los datos\n","print(\"El arreglo x de la variable independiente tiene dimensión:\",x.shape)\n","print(\"El arreglo y de la variable dependiente tiene dimensión\",y.shape)"],"metadata":{"id":"KBV93nRtlsQq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego, usaremos el modelo ```LinearRegression()``` de Scikit-learn para ajustar los datos y construir la mejor linea posible:"],"metadata":{"id":"-pMRsReDw4Ie"}},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","model = LinearRegression(fit_intercept=True)# generamos una instancia del modelo, el valor de fit_intercept es por defecto True,\n","                                            # lo dejamos para recordar que también se puede desacartar dejandolo en False.\n","\n","model.fit(x, y) # Entrenamos el modelo, ojo, se agrega una dimensión al arreglo x para que sea un vector columna\n","\n","xfit = np.linspace(0, 10, 1000)          # simulamos algunos datos para visualizar el modelo\n","yfit = model.predict(xfit[:, np.newaxis])# agregamos un nuevo eje para que la dimensión sea de (1000,1) un vector columna\n","\n","plt.scatter(x,y)\n","plt.plot(xfit, yfit,'black')\n","plt.xlabel('x'); plt.ylabel('y')\n","plt.legend([\"Predicciones\",\"Datos originales\"])\n","#graficamos segmentos de recta que indique el error entre la predicción y el valor real\n","plt.plot(np.hstack([x,x]).T, np.hstack([y, model.predict(x)]).T, color=\"red\");\n"],"metadata":{"id":"l9JEIDG7w6Sn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La regresión lineal trata de minimizar la suma de los errores al cuadrado $\\sum_i (y[i] - \\hat{y}[i])^2$; esta es la suma de la longitud de los segmentos rojos en el gráfico de arriba. Los valores estimados $\\hat{y}[i]$ son denotados por `yfit` en el código anterior."],"metadata":{"id":"uKKSiK7vzHhe"}},{"cell_type":"markdown","metadata":{"id":"VojYo-1PwcRr"},"source":["La pendiente y el intercepto los podemos obtener desde el modelo definido y previamente ajustado con el método ```fit```"]},{"cell_type":"code","source":["print(\"Pendiente del modelo:\", model.coef_[0])\n","print(\"Intercepto:\", model.intercept_)"],"metadata":{"id":"ygiLBUvYzLu9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este ejemplo, el coeficiente `model.coef_[0]` es la pendiente de la línea ajustada, y el intercepto `model.intercept_` es el punto donde la linea intersecta el eje-y. En scikit leran los parámetros aprendidos de este modelo u otro siempre tienen un guión bajo al final para indetificarlos fácilemnte.\n","\n","Notemos que los parámetros estimados por el modelo de regresión estuvieron bastante cerca de los valores reales de la recta simulada. Experimentar con el número de datos y desviación estándar de los errores introducidos y evaluar los resultados."],"metadata":{"id":"VYzLWs1V0ljf"}},{"cell_type":"markdown","source":["Por otro lado, las métricas de ajuste para evaluar el desempeño del modelo las podemos obtener con la función `mean_squared_error` y `r2_score` desde el paquete `sklearn.metrics`:"],"metadata":{"id":"FJ_CsHCE1ijP"}},{"cell_type":"code","source":["from sklearn.metrics import r2_score, mean_squared_error\n","print(\"El error MSE del modelo es: \", mean_squared_error(y, model.predict(x)))\n","print(\"El valor del coeficiente R2 es: \", r2_score(y, model.predict(x)))"],"metadata":{"id":"BTEe6XrM2FtS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Ejemplo 2. Regresión lineal simple con datos reales"],"metadata":{"id":"wwmOPqJi28tn"}},{"cell_type":"markdown","source":["Predicción del salario anual de una persona en relación a sus años de experiencia. En este ejemplo, volveremos al caso pendiente sobre regresión lineal univariada, agregando división del dataset en un set de entrenamiento y un set de prueba para evaluar nuestro modelo entrenado."],"metadata":{"id":"jxi0-kDYtGAv"}},{"cell_type":"markdown","source":["**A. Importamos paquetes de interés**"],"metadata":{"id":"2wSgAW7muW_p"}},{"cell_type":"code","source":["# sklearn - Machine Learning tradicional\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error\n","from sklearn.preprocessing import PolynomialFeatures"],"metadata":{"id":"vuO35-QqtGji"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**B. Cargamos los datos**"],"metadata":{"id":"miD3IB_IuhFL"}},{"cell_type":"markdown","source":["Antes de ejecutar la siguiente linea, subir el archivo a colab con alguno de los métodos descritos, dejarlo en la misma carpeta del notebook si se trabaja de forma local o indicar la dirección completa."],"metadata":{"id":"3ezB84507fXs"}},{"cell_type":"code","source":["dataset = pd.read_csv('Salary - Salary.csv')\n","dataset.head()"],"metadata":{"id":"rdt2H3LZucHu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Grafiquemos los datos para tener una vista de la relación que hay entre las variables\n","plt.scatter(dataset.YearsExperience,dataset.Salary,color='red')\n","plt.xlabel('Experiencia')\n","plt.ylabel('Salario')\n","plt.show()"],"metadata":{"id":"-xWCDf7e0vyj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**C. Extraer las variables de interés y guardarlas en numpy arrays:**\n","\n","\n","Recordar que con pandas, podemos acceder a los valores de las columnas indexando con las posiciones de estas usando el método `iloc` o a través del nombre usando `loc`, generemos entonces nuestras variables x e y"],"metadata":{"id":"3_P4X00p02Of"}},{"cell_type":"code","source":["x = dataset.iloc[:,[0]].values # años de experiencia quedan guardados como numpy array al extraer los valores\n","y = dataset.loc[:,['Salary']].values # salario anual\n","\n","print(\"Tamaño del arreglo x: \",x.size)\n","print(\"Forma  del arreglo x: \",x.shape)"],"metadata":{"id":"0LDCHldh1C1_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**D. Separamos el dataset completo en un set de entrenamiento y uno de prueba.**\n","\n","Para esto usaremos la función `train_test_split()`, esta recibe como argumentos la variable x e y, la proporción de los datos que serán dejados para prueba o entrenamiento (entre 0 y 1) o el número de muestras para test, además de [otros](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) parámetros."],"metadata":{"id":"elkS5tyI1Hm2"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)#20% de los datos serán dejados para test"],"metadata":{"id":"pr6GJ01r1O-a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**E. Regresión lineal**\n","* Creamos/instanciamos el modelo\n","* Entrenamos el modelo con el método ```fit```\n","* Hacemos predicciones sobre el conjunto de test con método predict\n","* Calculamos métricas de desempeño en train y test"],"metadata":{"id":"iIAq_Grr1WCH"}},{"cell_type":"code","source":["modelo_lineal = LinearRegression()#creamos modelo\n","modelo_lineal.fit(x_train,y_train)#entrenamiento\n","\n","# evaluamos en train\n","y_pred_train= modelo_lineal.predict(x_train)\n","# evaluación en test\n","y_pred_test = modelo_lineal.predict(x_test)\n","\n","\n","# calculamos las métricas de desempeño y las guardamos en un dataframe para evaluación o exportar resumen\n","MSE_train = mean_squared_error(y_train, y_pred_train )\n","MSE_test  = mean_squared_error(y_test, y_pred_test)\n","R2_train  = r2_score(y_train, y_pred_train)\n","R2_test   = r2_score(y_test, y_pred_test)\n","\n","# dataframe conteniendo las métricas (solo para ordenarlos)\n","dmetricas = {'Train': [MSE_train, R2_train], 'Test': [MSE_test, R2_test]}# datos resumen\n","Resumendf = pd.DataFrame(dmetricas,index = ['MSE','R2_score'])\n","Resumendf"],"metadata":{"id":"3zTe1woL1a-F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**F. Visualización de resultados**"],"metadata":{"id":"oBdWRxvF1ppw"}},{"cell_type":"code","source":["plt.figure(figsize = (7,7))\n","plt.plot(x_train,y_train,'or',x_test,y_test,'og',x_train,y_pred_train,'-b')\n","plt.legend(['Train','Test'])\n","plt.xlabel('Experiencia')\n","plt.ylabel('Salario')\n","plt.show()"],"metadata":{"id":"Mcloy1Ui1tp3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observación**: en el ejemplo anterior las métricas de desempeño del modelo fueron calculadas en una porción de los datos, donde la separación inicial del conjunto de datos de entrenamiento y prueba fue aleatoria, hubiesen cambiado las métricas si tenemos una separación diferente? Si! qué hacemos entonces para tener una evaluación del modelo más realista? podemos aplicar la técnicas de **Validación Cruzada**."],"metadata":{"id":"S0Wf_GFP1xtF"}},{"cell_type":"markdown","source":["##2. Validación Cruzada"],"metadata":{"id":"5la3ng9Sqb4e"}},{"cell_type":"markdown","source":["En los ejemplos anteriores, la validación más simple de los modelos consistió en:\n","* dividir el conjunto de datos en dos subconjuntos: uno de entrenamiento y otro de prueba\n","* ajustar el modelo en el conjunto de entrenamiento\n","* estimar el error de entrenamiento en el conjunto de entrenamiento\n","* estimar el error de prueba en el conjunto de prueba.\n","\n","Sin embargo, para evaluar la robustez del modelo y su capacidad de generalización, no es suficiente con este procedimiento. En particular, si el conjunto de datos es pequeño, el error de prueba será inestable y no reflejará la verdadera tasa de error que podríamos observar con el mismo modelo en un conjunto de datos de prueba de tamaño grande. De hecho, dado que la separación es aleatoria de los datos, puede darse el caso que las muestras de prueba favorezcan (solo por casualidad) la tarea de predicción del modelo.\n","\n","Para tener entonces una mejor evaluación del desempeño del modelo, aquí nos puede ayudar la técnica de **validación cruzada**.Esta técnica permite evaluar la **robustez** de un modelo predictivo al repetir el proceso de división del conjunto de datos. Esto nos dará muchos errores de entrenamiento y prueba y por consiguiente una estimación de la variabilidad del desempeño del modelo.\n","\n","Existen diferentes tipos de estrategias de validación cruzada (ej. K-fold cross validation, Leave One Out, Suffle Split, Stratified k-fold, etc.), en este práctico nos enfocaremos en la del tipo \"suffle-split\" (o división con revolvimiento aleatorio de los datos). En cada iteración de esta estrategia tendremos que:\n","\n","* revolver aleatoriamente el orden de las muestras de una copia del conjunto de datos completo;\n","* dividir el conjunto de datos en uno de entrenamiento y otro de prueba;\n","* entrenar el nuevo modelo en el conjunto de entrenamiento;\n","* evaluar el error de prueba en el conjunto de prueba.\n","\n","Este procedimiento se repite `n_splits` veces. Tener presente que estos procedimientos implican evaluar `n_splits`modelos, lo que incrementa el tiempo de computacional.\n","\n","<center><img src=https://inria.github.io/scikit-learn-mooc/_images/shufflesplit_diagram.png width=\"850\" ></center>\n","\n","\n","[fuente](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_train_test.html)"],"metadata":{"id":"KotnQm4V6YMG"}},{"cell_type":"markdown","source":["En la figura anterior, se muestra el caso particular de la estrategia de validación cruzada **shuffle-split** usando `n_splits = 5`.\n","\n","Para el Ejemplo 2 del bloque anterior de regresión lineal simple implementemos esta estrategia y evaluemos los resultados."],"metadata":{"id":"1SP3c5xOFtyS"}},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import ShuffleSplit\n","\n","regressor = LinearRegression()#creamos modelo\n","\n","cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n","cv_results = cross_validate( regressor, x, y, cv=cv, scoring=\"neg_mean_absolute_error\")"],"metadata":{"id":"hE-ndwMZGhMq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Los resultados `cv_results`son almacenados en un diccionario de python. Lo convertiremos a un `DataFrame`de pandas para visualizarlo y manipularlo más facilmente."],"metadata":{"id":"G_wgm8rzGs3i"}},{"cell_type":"code","source":["import pandas as pd\n","\n","cv_results = pd.DataFrame(cv_results)\n","cv_results.head()"],"metadata":{"id":"Qu9aPe0bIS83"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**NOTAS**\n","\n","Un **score** es una métrica para la cual valores más grandes significan mejores resultados. Por el contrario, una metrica de error indicará mejores resultados cuando sus valores sean más pequeños. El parámetro `scoring` en `cross_validate` siempre espera una función que es un score.\n","\n","En sci-kit learn, todas las métricas de error como la de `mean_absolute_error`, pueden ser transformadas a score para ser usadas en `cross_validate` por medio de anteponer el string `neg_` antes del nombre, com en este ejemplo `scoring = \"neg_mean_absolute_error\"`."],"metadata":{"id":"2MVU1cfFIYu8"}},{"cell_type":"markdown","source":["En nuestro caso, revirtamos la negación para obtener el valor del error correspondiente y observemos algunos de los valores:"],"metadata":{"id":"ew6GmP7TXCn6"}},{"cell_type":"code","source":["cv_results[\"test_error\"] = -cv_results[\"test_score\"]\n","cv_results.head()"],"metadata":{"id":"vdLf6XPPXeOT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resumamos los resultados en términos de un error de prueba medio y su variabilidad indicada por la desviación estándar:"],"metadata":{"id":"MF7DmZBeYOhN"}},{"cell_type":"code","source":["print(f\"El promedio de el error de prueba usando validación cruzada es: \"\n","      f\"{cv_results['test_error'].mean():.2f} $\")"],"metadata":{"id":"Q2ALkafCYZ0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"La desviación estándar del error de prueba es: \"\n","      f\"{cv_results['test_error'].std():.2f} $\")"],"metadata":{"id":"N7wdbGQYZdaZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estas métricas serán mas realistas para reportar el desempeño del modelo. Finalmente, si queremos hacer predicciones sobre datos nuevos, con qué modelo lo hacemos? En este caso se sugiere entrenar el modelo seleccionado (en este caso solo tenemos uno de tipo lineal) en todo el conjunto de datos original, teniendo en cuenta que las métricas de desempeño son las calculadas con la estrategia anterior."],"metadata":{"id":"QfSneZWDahau"}},{"cell_type":"markdown","source":["Finalmente, para seleccionar un modelo cuando estamos analizando varias alternativas, podemos hacerlo comparando sus métricas usando la estrategia descrita. Notar que tanto el valor promedio de las métricas o scores y la desviación estándar son importantes. Si dos modelos entregan métricas promedio similares, se prefiere el que tenga una desviación estándar menor."],"metadata":{"id":"h6TkQpSubFC-"}},{"cell_type":"markdown","source":["**Preguntas adicionales**\n","- ¿Podemos obtener más de una métrica usando `cross_validate`? por ejemplo, el coeficiente $R^2$, y las métricas obtenidas en los conjuntos de entrenamiento. Buscar en la documentación e implementarlo\n","- Sci-kit learn también implementa validación cruzada del tipo [K-Fold](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators), al respecto, mencione alguna ventaja de la estrategia implementada en esta práctica sobre la del tipo K-Fold."],"metadata":{"id":"Cjeq8f4qYa0I"}},{"cell_type":"markdown","source":["##3. Regresión polinomial"],"metadata":{"id":"iFLitczgsUX4"}},{"cell_type":"markdown","source":["En este caso nos interesa ajustar un polinomio de grado n a los datos. El polinomio tiene la siguiente forma:\n","$$\n","y = a_0 + a_1*x + a_2*x^2+...+a_n*x^n\n","$$"],"metadata":{"id":"P-llUUT7aEOB"}},{"cell_type":"markdown","source":["Primero simulamos el conjunto de datos:"],"metadata":{"id":"N37My6P8aIOC"}},{"cell_type":"code","source":["Np = 100 # número de datos a simular\n","X  = 8*np.random.rand(Np,1)-4\n","y  = 0.5*X**2 + X + 2 + np.random.randn(Np,1)\n","plt.scatter(X, y);"],"metadata":{"id":"TolNqjDIsX7E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Claramente los datos no pueden ser ajustados con una linea recta, en este caso, necesitaremos ajustar una parábola o polinomio de grado 2. Para esto usaremos el `PolynomialFeatures()` para incluir estas transformaciones polinómicas sobre las características y así poder ocupar el modelo de regresión lineal (en los parámetros) para estimar los coeficientes del polinomio."],"metadata":{"id":"ZO6iz_7MaMtx"}},{"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures\n","poly_features = PolynomialFeatures(degree = 2, include_bias=False)    # Definimos la transformación\n","X_poly        = poly_features.fit_transform(X)                        # Aplicamos la transformación"],"metadata":{"id":"OesgUVx5aP77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Primer dato original: \",X[0])\n","print(\"Primer dato transformado: \",X_poly[0])"],"metadata":{"id":"AGhx8IwBaR5R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora, además de incluir el dato original x se incluye su valor al cuadrado. Ahora ajustemos los datos usando el modelo de regresión lineal  `LinearRegression()`"],"metadata":{"id":"fEEyPP0EaXbY"}},{"cell_type":"code","source":["pol_reg = LinearRegression()\n","pol_reg.fit(X_poly,y)\n","print('Intercepto estimado: ',pol_reg.intercept_)\n","print('Coeficientes polinomio: ',pol_reg.coef_)"],"metadata":{"id":"ukppX_4salh4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizamos los resultados:"],"metadata":{"id":"oIDBO3CMafGZ"}},{"cell_type":"code","source":["xfit = np.linspace(-4, 4, 1000)\n","yfit = pol_reg.predict(poly_features.fit_transform(xfit[:, np.newaxis]))\n","\n","plt.scatter(X, y)\n","plt.plot(xfit, yfit,'r');\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend([\"Predicciones\",\"Datos originales\"])\n","plt.show()"],"metadata":{"id":"Oqv0c5MAahyB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4. Regresión lineal multivariada"],"metadata":{"id":"oECBhCfTbZcH"}},{"cell_type":"markdown","source":["Antes de resolver el problema, es importante recordar que muchos de los modelos que usaremos, tanto supervisados como no supervisados, requieren que los datos tanto en la matriz de características como la variable objetivo, se ordenen de cierta forma, en particular como se muestra en la siguiente figura:\n","\n","<center>\n","    <img width=\"60%\" src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.02-samples-features.png\">\n","</center>\n","\n","\n","[fuente](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html)\n"],"metadata":{"id":"BfPIlMgccmiw"}},{"cell_type":"markdown","source":["**A. Dataset**\n","\n","Los datos que usaremos corresponden a datos de precio de propiedades de California, el *California housing dataset* disponibles en `sklearn.datasets`."],"metadata":{"id":"gZNEhyOHdOnI"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","\n","housing = fetch_california_housing(as_frame=True)\n","data, target = housing.data, housing.target"],"metadata":{"id":"Ogl79f1YrCFf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este conjunto de datos el objetivo es predecir la mediana del valor de casa en un área de California. Las características (features) coleccionados se basaron en información geográfica e inmobiliarios en general.\n","\n","Veamos algunos detalles del conjunto de datos:"],"metadata":{"id":"U-Ngl9hhrIA-"}},{"cell_type":"code","source":["print(housing.DESCR)"],"metadata":{"id":"Seny8itvrr9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"DftPvbcprvp-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para simplificar las visualizaciones futuras, transformemos los precios del rango 100(k\\$) al de miles de dólares (k\\$)"],"metadata":{"id":"Bbhi_m8Vr_iG"}},{"cell_type":"code","source":["target *= 100\n","target.head()"],"metadata":{"id":"k6n1UNJcr-kP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**B. Separación de datos y entrenamiento**"],"metadata":{"id":"IwGJKzX7t7a3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","\n","# Dividimos el dataset entre el conjunto de entrenamiento y prueba\n","data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3)\n","\n","modelo_lineal_MV = LinearRegression()# creamos instancia del modelo\n","modelo_lineal_MV.fit(data_train,target_train)# entrenamiento"],"metadata":{"id":"HjG9xiV6t63d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**C. Probamos en conjunto de test y evaluamos algunas métricas**"],"metadata":{"id":"8Vswuxtbu-wu"}},{"cell_type":"code","source":["from sklearn.metrics import r2_score, mean_squared_error\n","\n","# evaluación en train\n","target_pred_train= modelo_lineal_MV.predict(data_train)\n","# evaluación en test\n","target_pred_test = modelo_lineal_MV.predict(data_test)\n","\n","\n","# cálculo de métricas de desempeño y las guardamos en un dataframe para evaluación o exportar resumen\n","MSE_train = mean_squared_error(target_train, target_pred_train )\n","MSE_test  = mean_squared_error(target_test, target_pred_test)\n","R2_train  = r2_score(target_train,target_pred_train)\n","R2_test   = r2_score(target_test, target_pred_test)\n","\n","# dataframe conteniendo las métricas\n","dmetricas = {'Train': [MSE_train, R2_train], 'Test': [MSE_test, R2_test]}# datos resumen\n","Resumendf = pd.DataFrame(dmetricas,index = ['MSE','R2_score'])\n","Resumendf\n"],"metadata":{"id":"Pq3OhaTDu-W-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**D. Visualizamos los resultados**"],"metadata":{"id":"vBVF_ECpvx79"}},{"cell_type":"code","source":["plt.figure(figsize = (7,7))\n","plt.scatter(target_test,target_pred_test, color = 'red')\n","plt.xlabel('Valor de prueba real')\n","plt.ylabel('Valor de prueba predicho')\n","plt.show()"],"metadata":{"id":"EHi8swmtvxan"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El gráfico anterior nos dice que el modelo no tiene la capacidad suficiente para representar correctamente la relación entre los atributos y la variable objetivo a predecir, si fuese un modelo adecuado, los puntos en el gráfico de dispersión anterior tenderían a quedar en una linea recta."],"metadata":{"id":"bMRWBhJ5yNTE"}},{"cell_type":"markdown","source":["### Mejorando los resultados\n","\n","Para mejorar los resultados tenemos varias opciones, por ejemplo:\n","* Cambiar el tipo de modelo de regresión (existen varios disponibles en Sci-kit learn)\n","* Incluir nuevas variables transformadas (ej. agregando factores polinomiales) o preprocesamiento previo (ej. estandarizado de los datos).\n","\n","* Incluir técnicas de regularización a los modelos que lo permitan, etc.\n","\n","En el siguiente ejemplo, las predicciones se harán implementando un modelo lineal en los coeficientes que además incluya interacciones entre las variables, ej. x1*x2, x1*x3,..."],"metadata":{"id":"9kkt97E_wD-s"}},{"cell_type":"code","source":["# Creamos nuevas variables a partir de los features originales, para incluir interacciones\n","from sklearn.preprocessing import PolynomialFeatures\n","inter = PolynomialFeatures(interaction_only=True,include_bias = False)# solo considera interacciones, no potencias\n","Xinter_train = inter.fit_transform(data_train)\n","Xinter_test  = inter.transform(data_test)"],"metadata":{"id":"82758cPOy5gQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ojo, que ahora el número de características aumentó al incluir las interacciones\n","print(\"Forma original del conjunto de entrenamiento: \",data_train.shape)\n","print(\"Nueva forma del conjunto de entrenamiento: \",Xinter_train.shape)"],"metadata":{"id":"i4V1hj1Uy93H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelo_lineal_Inter = LinearRegression()# creamos modelo para incluir interacciones\n","modelo_lineal_Inter.fit(Xinter_train,target_train)# entrenamiento\n","\n","# evaluación en test\n","y_pred_test  = modelo_lineal_Inter.predict(Xinter_test)\n","y_pred_train = modelo_lineal_Inter.predict(Xinter_train)\n","\n","# cálculo de métricas de desempeño y las guardamos en un dataframe para evaluación o exportar resumen\n","MSE_train = mean_squared_error(target_train, y_pred_train)\n","MSE_test  = mean_squared_error(target_test, y_pred_test)\n","R2_train  = r2_score(target_train, y_pred_train)\n","R2_test   = r2_score(target_test, y_pred_test)\n","\n","# dataframe conteniendo las métricas\n","dmetricas = {'Train': [MSE_train, R2_train], 'Test': [MSE_test, R2_test]}# datos resumen\n","Resumendf = pd.DataFrame(dmetricas,index = ['MSE_inter','R2_score_inter'])\n","Resumendf"],"metadata":{"id":"yfw2G0bK0i4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualización de resultados\n","plt.figure(figsize = (7,7))\n","plt.scatter(target_test,y_pred_test, color = 'blue')\n","plt.xlabel('Valor de prueba real')\n","plt.ylabel('Valor de prueba predicho con modelo incluyendo interacciones')\n","plt.show()"],"metadata":{"id":"LhjUFQzu0wqH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hubo una ligera mejora, pero aún se puede incrementar. Probemos utilizando otros modelos disponibles en `sci-kit learn`. En el siguiente ejemplo implementaremos lo anterior y además implementaremos la estrategia de validación cruzada para tener una mejor idea del comportamiento de los modelos en relación a su capacidad de generalización."],"metadata":{"id":"5ECtQUv31MHH"}},{"cell_type":"markdown","source":["**A. Primero importemos los modelos disponibles**"],"metadata":{"id":"9NkBRUBY22TW"}},{"cell_type":"code","source":["# import warnings filter\n","from warnings import simplefilter\n","# ignore all future warnings\n","simplefilter(action='ignore', category=FutureWarning)\n","\n","# Para ejecutar validación cruzada\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import ShuffleSplit\n","\n","# Diferentes modelos disponibles en sci-kit learn\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import ElasticNet\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import BayesianRidge\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor"],"metadata":{"id":"Bh07GGPC27So"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**B. Definamos algunos ajustes previos al entrenamiento y creemos las instancias de los modelos.**"],"metadata":{"id":"haTwmnYY3DG1"}},{"cell_type":"code","source":["# variables de usuario a ajustar\n","SEED       = 9\n","FOLDS      = 10\n","SCORE_REG  = [\"neg_mean_squared_error\",\"r2\"] #en este caso, un score es una variable cuyo valor mientras mayor sea mejor es el resultado evaluado, acá usamos el negativo del MSE para pasarlo como argumento a la validación cruzada, yaque trabaja con scores.\n","\n","# hold different regression models in a single dictionary\n","models = dict()\n","models[\"Linear\"]        = LinearRegression()\n","models[\"Lasso\"]         = Lasso()\n","models[\"ElasticNet\"]    = ElasticNet()\n","models[\"Ridge\"]         = Ridge()\n","models[\"BayesianRidge\"] = BayesianRidge()\n","models[\"KNN\"]           = KNeighborsRegressor()\n","models[\"DecisionTree\"]  = DecisionTreeRegressor()\n","models[\"AdaBoost\"]      = AdaBoostRegressor()\n","models[\"GradientBoost\"] = GradientBoostingRegressor()\n","models[\"RandomForest\"]  = RandomForestRegressor()"],"metadata":{"id":"lp1mBEli3Sus"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 10-fold cross validation para cada modelo\n","MSE_Test  = list()\n","MSE_Train = list()\n","R2_Test   = list()\n","R2_Train  = list()\n","model_names   = list()\n","CV            = ShuffleSplit(n_splits=FOLDS, test_size = 0.3, random_state=SEED)\n","for model_name in models:\n","    model   = models[model_name]\n","\n","    cv_results = cross_validate(model, data, target, cv=CV, scoring=SCORE_REG,return_train_score=True)\n","\n","    MSE_Test.append(-cv_results[\"test_neg_mean_squared_error\"])# MSE en Test\n","    MSE_Train.append(-cv_results[\"train_neg_mean_squared_error\"])# MSE en Train\n","    R2_Test.append(cv_results[\"test_r2\"])# R2 en Test\n","    R2_Train.append(cv_results[\"train_r2\"])# R2 en Train\n","\n","    model_names.append(model_name)\n","    print(\"MSE en TEST modelo {:>20}: {:.2f}, {:.2f}\".format(model_name, round( -cv_results[\"test_neg_mean_squared_error\"].mean(), 3), round(cv_results[\"test_neg_mean_squared_error\"].std(), 3)))\n"],"metadata":{"id":"Rf1bKprw3pEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráficos de caja para comparar el resultado del MSE de los modelos en TEST\n","figure = plt.figure(figsize = (10,6));\n","ax1 = figure.add_subplot(111);\n","plt.boxplot(MSE_Test);\n","ax1.set_xticklabels(model_names, rotation = 45, ha=\"right\");\n","ax1.set_ylabel(\"Error cuadrático medio (MSE)\");\n","ax1.set_title('Comparación de modelos de regresión en TEST')\n","plt.margins(0.05, 0.1);\n","plt.show();\n",""],"metadata":{"id":"bjS1DqSh9Qy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráficos de caja para comparar el resultado del MSE de los modelos en TRAIN\n","figure = plt.figure(figsize = (10,6));\n","ax2 = figure.add_subplot(111);\n","plt.boxplot(MSE_Train);\n","ax2.set_xticklabels(model_names, rotation = 45, ha=\"right\");\n","ax2.set_ylabel(\"Error cuadrático medio (MSE)\");\n","ax2.set_title('Comparación de modelos de regresión en TRAIN')\n","plt.margins(0.05, 0.1);\n","plt.show();"],"metadata":{"id":"sxi3EG6PEPOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["¿Qué puede concluir de los resultados anteriores?\n"],"metadata":{"id":"9wLYAxr8cutC"}},{"cell_type":"markdown","source":["##4. Ajuste de curvas con funciones no lineales"],"metadata":{"id":"l8rhK5pdsYZi"}},{"cell_type":"markdown","source":["A diferencia de los problemas anteriores, en este caso al menos uno de los parámetros a estimar no está combinado linealmente con los datos, i.e. puede ser parte del exponente en una función exponencial, o el argumento de una función trigonométrica, etc.\n","\n","Estos problemas generalmente aparecen en análisis de datos experimentales donde los modelos son conocidos y contienen no linealidades, ej:\n","\n","* Modelo de la corriente en un circuito alterno: $I(t)=Asin(2\\pi f\\cdot t+\\phi)\n","+\\epsilon$\n","\n","* Modelo de la corriente de un diodo: $I_D = I_S\\cdot\\left(e^{\\frac{V_D}{nV_T}}-1\\right)$\n","\n","* Respuesta temporal de un sistema de segundo orden sub-amortiguado ante entrada escalón: $y(t) = 1 - \\frac{e^{-\\xi\\omega_n t}}{\\sqrt{(1-\\xi^2)}}\\cdot sin\\left(\\omega_n\\sqrt{(1-\\xi^2)}\\cdot t+\\phi   \\right)$\n"],"metadata":{"id":"jQghep-KLj48"}},{"cell_type":"markdown","source":["###Ejemplo 1. Identificación de un sistema dinámico de primer orden\n","\n","En este ejemplo estudiaremos la respuesta de un sistema dinámico de primer orden ante una entrada de tipo escalón unitario (función de Heaviside con amplitud 1). El modelo que rige la respuesta (salida) del sistema ante este tipo de estímulo es bien conocido y tiene la siguiente forma:\n","\n","$$\n","y(t) = k (1-e^{-t/\\tau}), t\\geq0\n","$$\n","\n","donde:\n","\n","$y$: es la respuesta del sistema\n","\n","$k$: es la ganancia del sistema\n","\n","$t$: es el tiempo en seg\n","\n","$\\tau$: es la constante de tiempo, i.e. tiempo para el cual la respuesta alcanza $\\approx 63\\%$ del valor final."],"metadata":{"id":"G3pzOoXJRkAn"}},{"cell_type":"markdown","source":["Partamos por simular unos datos asumiendo algunos valores de los parámetros de interés del sistema, ej. $k=2.5$ y $\\tau=1.0$"],"metadata":{"id":"ZPV5qlNbT8sR"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(10)# para asegurar reproducibilidad\n","Np      = 100 # número de puntos a simular\n","k_real  = 2.5\n","tau_real= 1.0\n","t       = np.linspace(0,10,Np)\n","y       = k_real*(1-np.exp(-t/tau_real)) + 0.1*np.random.randn(Np)# añadimos ruido para hacer más realista la simulación\n","\n","# graficamos los datos\n","plt.plot(t,y,linewidth=1.5)\n","plt.xlabel('Tiempo (seg)'); plt.ylabel('Amplitud (u.a.)')\n","plt.axis([0, t[-1], 0, 3])\n","plt.show()"],"metadata":{"id":"uX7mK3rXUP9S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para ajustar el modelo a los datos simulados usaremos la libería SciPy."],"metadata":{"id":"NUsIKTTUWevk"}},{"cell_type":"code","source":["from scipy.optimize import curve_fit\n","\n","#1. Primero definimos el modelo que rige a los datos\n","def fun(t,k,tau):\n","    return k*(1-np.exp(-t/tau))\n","\n","#2. Ajustamos el modelo a los datos\n","init_values   = [2,0.5]#valores iniciales, suposición según conocimiento experto, pueden no incluirse\n","best_fit, cov = curve_fit(fun,t,y,p0=init_values)\n","\n","print(f\"Los parámetros estimados son k:{best_fit[0]} y tau:{best_fit[1]}\")\n"],"metadata":{"id":"-WbGIzndOkGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. graficamos los datos\n","plt.figure(figsize=(8,5))\n","plt.plot(t,y,'-b',t,fun(t,best_fit[0],best_fit[1]),'--r',linewidth=1.5)\n","plt.xlabel('Tiempo (seg)'); plt.ylabel('Amplitud (u.a.)')\n","plt.axis([0, t[-1], 0, 3])\n","plt.legend(['Datos','Ajuste'])\n","plt.show()"],"metadata":{"id":"eagg2blzTDm5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Ejercicios"],"metadata":{"id":"4jRLFIemsfvH"}},{"cell_type":"markdown","source":["**Ejercicio 1. Regresión lineal con una variable independiente**\n","\n","En este ejercicio usaremos el conjunto de datos adjunto: *penguins_regression.csv* para predecir el peso de pingüinos en función de la longitud de su aleta.\n","\n","Para esto se pide:\n","1. Cargar los datos y explorarlos.\n","2. Dividir el conjunto de datos en uno de entrenamiento y otro de prueba con `train_test_split()`\n","3. Crear el modelo de regresión con el objeto `LinearRegression()` de `sci-kit learn`\n","4. Entrenar el modelo\n","5. Indicar los valores de la pendiente y coeficiente de posición\n","6. Graficar los datos en un gráfico de dispersión e incluir una simulación del modelo sobre estos (la linea recta con los parámetros encontrados)\n","7. Calcular las métricas de regresión (MSE, RMSE y $R^2$) sobre ambos conjuntos de datos y comentarlas. Qué ventaja tiene la métrica RMSE sobre el MSE?\n","8. Si entrenamos el mismo modelo usando validación cruzada, cómo cambian las métricas de desempeño para modelo?"],"metadata":{"id":"tyT3oJwdFndh"}},{"cell_type":"code","source":["# Cargamos los datos\n","pinguinos    = pd.read_csv(\"penguins_regression.csv\")# primero subirlos a colab\n","feature_name = \"Longitud Aleta (mm)\"\n","target_name  = \"Masa Corporal (g)\"\n","data, target = pinguinos[[feature_name]], pinguinos[target_name]"],"metadata":{"id":"e5DkmaIWV4Gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Código aquí"],"metadata":{"id":"tkIbmAmQsfVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ejercicio 2. Regresión multivariada**\n","\n","Usando validación cruzada, seleccionar el mejor modelo para los datos de estimación de fuerza de compresión de concreto estudiados en el práctico de Pandas.\n","\n","Realizar además un gráfico de dispersión entre los valores predichos y valores reales de la variable target para el mejor modelo estimado y reportar las métricas medias junto a su desviación estándar para dicho modelo. Justifique su selección."],"metadata":{"id":"nkZoU7_iNOh1"}},{"cell_type":"code","source":["# Código aquí"],"metadata":{"id":"6hRw_366NXBT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Referencias"],"metadata":{"id":"Ha_PSAkjsi7-"}},{"cell_type":"markdown","source":["- Parte de los ejemplos fueron adaptados del MOOC de Sci-kit learn: https://www.fun-mooc.fr/en/courses/machine-learning-python-scikit-learn/"],"metadata":{"id":"iHNW7SJLeXTY"}}]}