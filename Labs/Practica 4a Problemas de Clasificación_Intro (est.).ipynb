{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLEprfBH+LvhrUQ2xMcm55"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Práctica 4a: Problemas de Clasificación Intro.**\n","\n","Curso: Inteligencia Artificial para Ingenieros\n","\n","Prof. Carlos Toro N. (carlos.toro.ing@gmail.com)\n","\n","2022"],"metadata":{"id":"DV45IZ9474vp"}},{"cell_type":"markdown","source":["**Introducción**"],"metadata":{"id":"gcYaBcWu8NH4"}},{"cell_type":"markdown","source":["Una de las tares típicas que tratan de resolver las técnicas de machine learning es la de clasificar datos, para esto existen infinidad de técnicas, donde la elección de una u otra dependerá del tipo y cantidad de datos que tengamos. El objetivo en este caso es entonces tomar muestras representadas con $n$ variables para asignarles alguna etiqueta, clase o variable discreta $C_k$.\n","\n","$$\n","\\begin{align}y = f(x,\\theta),  y \\in \\{C_1,...,C_k,...,C_K-1,C_K\\}\\end{align}\n","$$\n"],"metadata":{"id":"MYwBZnFIDoQt"}},{"cell_type":"markdown","source":["donde $y$ es la variable discreta/clase/categoría/etiqueta a predecir, que puede tomar alguno de los $K$ valores objetivo. $x$ es un vector de $n$ características/variables o features que describen una muestra.\n","\n","En el caso de una clasificación que intente predecir solo 2 estados, ej. ON/OFF, SI/NO, FALLA/NO FALLA, CALOR/FRIO, etc. $K = 2$, hablaremos de una clasificación binaria. $f$ es el modelo clasificador o simplemente clasificador, y $\\theta$ son los parámetros que se optimizarán durante el entrenamiento."],"metadata":{"id":"TEcwzWFrFD3M"}},{"cell_type":"markdown","source":["**En esta práctica veremos:**\n","\n","1. Regresión logística\n","3. Evaluación del desempeño de modelos de clasificación usando diferentes métricas\n","4. Visualizaciones en problemas de clasificación\n","5. Validación cruzada para clasificación\n","6. Ejercicios"],"metadata":{"id":"WyqQiDJb8RI3"}},{"cell_type":"markdown","source":["## **Clasificación binaria con Regresión Logística**"],"metadata":{"id":"f0hiF1lJDea1"}},{"cell_type":"markdown","source":["Crearemos un ejemplo introductorio usando una versión del dataset ``penguins_classification.csv``. Para simplificar el problema, trataremos de predecir solo la especie de 2 de los pingüinos basado en la información extraida de la medición de sus picos (culmen)"],"metadata":{"id":"ysU8YHO-XzT3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q02o2xWhhoWv"},"outputs":[],"source":["import pandas as pd\n","\n","penguins = pd.read_csv(\"https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/datasets/penguins_classification.csv\")\n","\n","# solo usaremos las clases Adelie y Chinstrap\n","penguins = penguins.set_index(\"Species\").loc[[\"Adelie\", \"Chinstrap\"]].reset_index()\n","culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n","target_column = \"Species\""]},{"cell_type":"code","source":["penguins"],"metadata":{"id":"PCiKNGZ-oOxG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualicemos la distribución de las características para las clases:"],"metadata":{"id":"9iYPIR3HnupB"}},{"cell_type":"code","source":["import seaborn as sns\n","\n","sns.pairplot(penguins,hue = \"Species\",diag_kind=\"hist\")"],"metadata":{"id":"5dQpeR5ln1Xs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notemos que tenemos un problema bastante simple de resolver. Cuando la longitud del culmen aumenta, la probabilidad de que la especie de pinguino sea Chinstrap es cercana a 1. Sin embargo, al observar la distribución de la profundidad del culmen por si sola, vemos que no es muy útil para clasificar la especie.\n","\n","Para ajustar el modelo, separemos el conjunto de datos en uno de entrenamiento y otro de prueba:"],"metadata":{"id":"hPKmYr4DqhzF"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","penguins_train, penguins_test = train_test_split(penguins, test_size=0.2, random_state=2)\n","\n","data_train = penguins_train[culmen_columns].values\n","data_test = penguins_test[culmen_columns].values\n","\n","target_train = penguins_train[target_column]\n","target_test = penguins_test[target_column]"],"metadata":{"id":"8E3Qj9WIrheu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creamos el modelo y lo ajustamos:"],"metadata":{"id":"wHEQgFdnsLk4"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression # importamos el modelo de regresión logística que usaremos en esta práctica\n","\n","logistic_regression = LogisticRegression(penalty=\"none\")\n","logistic_regression.fit(data_train, target_train)\n","accuracy = logistic_regression.score(data_test, target_test)\n","\n","print(f\"La exactitud en el conjunto de prueba es: {accuracy:.3f}\")"],"metadata":{"id":"i7DH02Rht6zD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creemos la matriz de confusión y otras métricas."],"metadata":{"id":"XIvHD6qrx1FA"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","LABELS = target_test.unique() # extraemos las clases únicas a predecir\n","\n","y_pred_test = logistic_regression.predict(data_test)\n","cm = confusion_matrix(target_test,y_pred_test,labels = LABELS)\n","print('La matriz de confusión es: \\n',cm)"],"metadata":{"id":"qNhoI3cdx0hQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Desplegamos la matriz de confusión con un mapa de intensidad:"],"metadata":{"id":"eyTvClrz11tc"}},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm,  display_labels=LABELS)\n","disp.plot()\n","plt.title(\"Matriz de confusión en datos de test\")\n","plt.show()"],"metadata":{"id":"JJroJKOr16mR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Otras métricas usando `classification_report`:"],"metadata":{"id":"b78uAnu82H3y"}},{"cell_type":"code","source":["print(classification_report(target_test, y_pred_test, target_names=LABELS))"],"metadata":{"id":"iDA5UYME2Oj6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Grafiquemos la frontera de decisión generada con el modelo, esto lo podemos hacer con la clase `DecisionBoundaryDisplay` en un plano 2D yaque estamos trabajando solo con dos features de los datos, para mas variables sería complicado, a menos que apliquemos alguna técnica de reducción de dimensionalidad previamente para simplificar el problema."],"metadata":{"id":"SNRyeUnWy2W0"}},{"cell_type":"code","source":["#Nota: la función DecisionBoundaryDisplay solo trabajará en versiones iguales o superiores a 1.1 de sci-kit learn,\n","# en colab, no permite actualizar a una de estas versiones por la versión de python (3.7) que maneja, pero dejaré\n","# el código para que puedan ejecturalo en en su versión de jupyter o código en sus PCs locales\n","import sklearn\n","sklearn_version = sklearn.__version__\n","\n","print(sklearn_version)"],"metadata":{"id":"C90Tvgye_pC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# versión de python en colab actual\n","!python --version"],"metadata":{"id":"D2M7y_YSKt7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ejecutar solo si se cumple el requisito de la versión de sklearn\n","import seaborn as sns\n","from sklearn.inspection import DecisionBoundaryDisplay\n","\n","DecisionBoundaryDisplay.from_estimator(logistic_regression, data_test, response_method=\"predict\", cmap=\"RdBu_r\", alpha=0.5)\n","sns.scatterplot(data=data_test, x=culmen_columns[0], y=culmen_columns[1],\n","                hue=target_column,\n","                palette=[\"tab:red\", \"tab:blue\"])\n","\n","_ = plt.title(\"Frontera de decisión del modelo entrenado\\n Regresión logística en los datos de prueba\")\n","plt.show()"],"metadata":{"id":"skyDDoIU3-il"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gráfico de frontera de decisión usando [utilidades](https://github.com/amueller/mglearn) desarrolladas por [A. Muller](https://amueller.github.io/) (uno de los creadores de sci-kit learn, todos los créditos a él), acá definimos manualmente las funciones de esa librería yaque presenta problemas de importación, ejecutar la siguiente porción de código:"],"metadata":{"id":"yHUk2BxBDy4-"}},{"cell_type":"code","source":["#@title Ejecutar funciones auxiliares\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap, colorConverter, LinearSegmentedColormap\n","import matplotlib as mpl\n","\n","cm_cycle = ListedColormap(['#0000aa', '#ff5050', '#50ff50', '#9040a0', '#fff000'])\n","cm3 = ListedColormap(['#0000aa', '#ff2020', '#50ff50'])\n","cm2 = ListedColormap(['#0000aa', '#ff2020'])\n","\n","# create a smooth transition from the first to to the second color of cm3\n","# similar to RdBu but with our red and blue, also not going through white,\n","# which is really bad for greyscale\n","\n","cdict = {'red': [(0.0, 0.0, cm2(0)[0]),\n","                 (1.0, cm2(1)[0], 1.0)],\n","\n","         'green': [(0.0, 0.0, cm2(0)[1]),\n","                   (1.0, cm2(1)[1], 1.0)],\n","\n","         'blue': [(0.0, 0.0, cm2(0)[2]),\n","                  (1.0, cm2(1)[2], 1.0)]}\n","\n","ReBl = LinearSegmentedColormap(\"ReBl\", cdict)\n","\n","\n","def discrete_scatter(x1, x2, y=None, markers=None, s=10, ax=None,\n","                     labels=None, padding=.2, alpha=1, c=None, markeredgewidth=None):\n","    \"\"\"Adaption of matplotlib.pyplot.scatter to plot classes or clusters.\n","    Parameters\n","    ----------\n","    x1 : nd-array\n","        input data, first axis\n","    x2 : nd-array\n","        input data, second axis\n","    y : nd-array\n","        input data, discrete labels\n","    cmap : colormap\n","        Colormap to use.\n","    markers : list of string\n","        List of markers to use, or None (which defaults to 'o').\n","    s : int or float\n","        Size of the marker\n","    padding : float\n","        Fraction of the dataset range to use for padding the axes.\n","    alpha : float\n","        Alpha value for all points.\n","    \"\"\"\n","    if ax is None:\n","        ax = plt.gca()\n","\n","    if y is None:\n","        y = np.zeros(len(x1))\n","\n","    unique_y = np.unique(y)\n","\n","    if markers is None:\n","        markers = ['o', '^', 'v', 'D', 's', '*', 'p', 'h', 'H', '8', '<', '>'] * 10\n","\n","    if len(markers) == 1:\n","        markers = markers * len(unique_y)\n","\n","    if labels is None:\n","        labels = unique_y\n","\n","    # lines in the matplotlib sense, not actual lines\n","    lines = []\n","\n","    current_cycler = mpl.rcParams['axes.prop_cycle']\n","\n","    for i, (yy, cycle) in enumerate(zip(unique_y, current_cycler())):\n","        mask = y == yy\n","        # if c is none, use color cycle\n","        if c is None:\n","            color = cycle['color']\n","        elif len(c) > 1:\n","            color = c[i]\n","        else:\n","            color = c\n","        # use light edge for dark markers\n","        if np.mean(colorConverter.to_rgb(color)) < .4:\n","            markeredgecolor = \"grey\"\n","        else:\n","            markeredgecolor = \"black\"\n","\n","        lines.append(ax.plot(x1[mask], x2[mask], markers[i], markersize=s,\n","                             label=labels[i], alpha=alpha, c=color,\n","                             markeredgewidth=markeredgewidth,\n","                             markeredgecolor=markeredgecolor)[0])\n","\n","    if padding != 0:\n","        pad1 = x1.std() * padding\n","        pad2 = x2.std() * padding\n","        xlim = ax.get_xlim()\n","        ylim = ax.get_ylim()\n","        ax.set_xlim(min(x1.min() - pad1, xlim[0]), max(x1.max() + pad1, xlim[1]))\n","        ax.set_ylim(min(x2.min() - pad2, ylim[0]), max(x2.max() + pad2, ylim[1]))\n","\n","    return lines\n","\n","def plot_2d_classification(classifier, X, fill=False, ax=None, eps=None,\n","                           alpha=1, cm=cm3):\n","    # multiclass\n","    if eps is None:\n","        eps = X.std() / 2.\n","\n","    if ax is None:\n","        ax = plt.gca()\n","\n","    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n","    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n","    xx = np.linspace(x_min, x_max, 1000)\n","    yy = np.linspace(y_min, y_max, 1000)\n","\n","    X1, X2 = np.meshgrid(xx, yy)\n","    X_grid = np.c_[X1.ravel(), X2.ravel()]\n","    decision_values = classifier.predict(X_grid)\n","    ax.imshow(decision_values.reshape(X1.shape), extent=(x_min, x_max,\n","                                                         y_min, y_max),\n","              aspect='auto', origin='lower', alpha=alpha, cmap=cm)\n","    ax.set_xlim(x_min, x_max)\n","    ax.set_ylim(y_min, y_max)\n","    ax.set_xticks(())\n","    ax.set_yticks(())\n","\n","def plot_2d_separator(classifier, X, fill=False, ax=None, eps=None, alpha=1,\n","                      cm=cm2, linewidth=None, threshold=None,\n","                      linestyle=\"solid\"):\n","    # binary?\n","    if eps is None:\n","        eps = X.std() / 2.\n","\n","    if ax is None:\n","        ax = plt.gca()\n","\n","    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n","    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n","    xx = np.linspace(x_min, x_max, 1000)\n","    yy = np.linspace(y_min, y_max, 1000)\n","\n","    X1, X2 = np.meshgrid(xx, yy)\n","    X_grid = np.c_[X1.ravel(), X2.ravel()]\n","    try:\n","        decision_values = classifier.decision_function(X_grid)\n","        levels = [0] if threshold is None else [threshold]\n","        fill_levels = [decision_values.min()] + levels + [\n","            decision_values.max()]\n","    except AttributeError:\n","        # no decision_function\n","        decision_values = classifier.predict_proba(X_grid)[:, 1]\n","        levels = [.5] if threshold is None else [threshold]\n","        fill_levels = [0] + levels + [1]\n","    if fill:\n","        ax.contourf(X1, X2, decision_values.reshape(X1.shape),\n","                    levels=fill_levels, alpha=alpha, cmap=cm)\n","    else:\n","        ax.contour(X1, X2, decision_values.reshape(X1.shape), levels=levels,\n","                   colors=\"black\", alpha=alpha, linewidths=linewidth,\n","                   linestyles=linestyle, zorder=5)\n","\n","    ax.set_xlim(x_min, x_max)\n","    ax.set_ylim(y_min, y_max)\n","    ax.set_xticks(())\n","    ax.set_yticks(())"],"metadata":{"cellView":"form","id":"6MpT0RGg6ROq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig = plt.figure(figsize=(7,5))\n","\n","plot_2d_separator(logistic_regression, data_test, fill=True, eps = 0.5, alpha=.4)\n","discrete_scatter(data_test[:,0], data_test[:,1], target_test)\n","\n","\n","plt.title(\"Frontera de decisión del modelo entrenado\\n Regresión logística en los datos de prueba\")\n","plt.xlabel(culmen_columns[0])\n","plt.ylabel(culmen_columns[1])\n","plt.legend(LABELS)\n","\n","# ajuste ejes (opcional)\n","plt.xticks(np.arange(data_test[:,0].min(),data_test[:,0].max(), step=5))\n","plt.yticks(np.arange(data_test[:,1].min(),data_test[:,1].max()))\n","plt.axis(\"tight\")\n","\n","plt.show()"],"metadata":{"id":"ziRTZktb3cWt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego, vemos que la función de decisión es representada por una linea seaparando las dos clases. En este caso, se usó una combinación de ambos features para graficar la frontera. Veamos ahora los valores de los coeficientes estimados para cada variable predictora para tener una idea de la importancia que le atribuye el modelo a cada una:"],"metadata":{"id":"JaXwJrza9a1f"}},{"cell_type":"code","source":["logistic_regression.coef_"],"metadata":{"id":"eIuzNK-n-mgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["coefs = logistic_regression.coef_[0]\n","weights = pd.Series(coefs, index=culmen_columns)"],"metadata":{"id":"slSxe0iV-L57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights.plot.barh()\n","_ = plt.title(\"Pesos de la regresión logística\")"],"metadata":{"id":"JFeMry5C-bvK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este caso, ambos coeficientes son no nulos. Si alguno de ellos hubiese sido cero, la frontera de decisión hubise sido o una recta horizontal o vertical.\n","\n","Más aún, el intercepto tambien es distinto de cero, lo que significa que la decisión no pasa por las coordenadas (0,0), este tiene un valor de:"],"metadata":{"id":"RMzIglQJ-2l5"}},{"cell_type":"code","source":["logistic_regression.intercept_"],"metadata":{"id":"S6KCOl51_OYB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para extraer alguna información acerca de la importancia de los coeficientes anteriores respecto a las variables que acompañan, las variables debieran estar en la misma escala o rango de valores, en el caso anterior no es así. La interpretación puede ser errónea si concluimos que la variable `Culmen Depth` es más importante para lograr la predicción, cuando ya vimos de los histogramas que la variable `Culmen Length` es la que facilita dicha discriminación entre especies. Resolvamos esto entrenando un modelo pero con las variables estandarizadas, es decir, cada columna de la matriz de datos tendrá media  = 0 y desv. estándar = 1."],"metadata":{"id":"JGYxYfX-Aqq4"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","\n","# Preprocesamiento de los datos (columnas), en este caso los estandaricemos, i.e. los dejaremos con media 0 y desviación estándar 1\n","scaler = StandardScaler()\n","X_data = scaler.fit_transform(penguins[culmen_columns])\n","# Modelo\n","LogReg_ss  = LogisticRegression()# generamos una instancia del modelo\n","\n","LogReg_ss.fit(X_data, penguins[target_column].values)# entrenamos en todos los datos, solo para evaluar los coeficientes\n","coefs = LogReg_ss.coef_[0]\n","weights_ss = pd.Series(coefs, index=culmen_columns)# coeficientes nuevo modelo\n","\n","# gráfico de barras con la amplitud de los pesos cuando el modelo se entrena con las variables estandarizadas\n","weights_ss.plot.barh()\n","_ = plt.title(\"Pesos de la regresión logística\")\n"],"metadata":{"id":"GgbqwS-ICjLx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A partir del gráfico, vemos que el resultado es mas coherente respecto a los histogramas iniciales, donde la variable `Culmen Length`está aportando mayor información al modelo para realizar la discriminación de especies. Hacer este pre-procesamiento para todos los modelos donde la interpretación de coeficientes u optimizados sea necesaria."],"metadata":{"id":"ouwL9yNuEO-X"}},{"cell_type":"markdown","source":["Finalmente, si volvemos al primer paso de división de los datos entre un conjunto de entrenamiento y otro de prueba, qué sucedería si tomamos otra división? se mantendrían las métricas? esto lo podemos verificar cambiando el valor de `random_state=2` a otro número, por ejemplo: `random_state=5`. Verificar.\n","\n","Cómo podemos entregar una métrica de desempeño más realista del modelo?\n","\n","R: **Usando validación cruzada.**"],"metadata":{"id":"eaG8NR1SyB1k"}},{"cell_type":"markdown","source":["### **Validación cruzada para mejorar el reporte de métricas de desempeño**"],"metadata":{"id":"YsBK9YLZAxtG"}},{"cell_type":"markdown","source":["**Recordemos**: La validación cruzada nos permitirá estimar la robustez de un modelo predictivo al repetir el procedimiento de división del conjunto de datos en conjuntos de *train* y *test*. Este procedimiento nos dará varios valores de métricas de desempeño en entrenamiento y prueba y por consiguiente alguna **estimación de la variabilidad del desempeño de generalización del modelo**.\n","\n","Aquí usaremos la estrategia de *K-fold cross validation*, que, como muestra la imagen de más abajo, subdivide el conjunto de datos en K grupos, probando el modelo K veces en una porción diferente de los datos.\n","\n","\n","<center><img src=https://scikit-learn.org/stable/_images/grid_search_cross_validation.png width=\"650\" ></center>\n","\n","\n","[fuente](https://scikit-learn.org/stable/modules/cross_validation.html)\n","\n","En el siguiente ejemplo no usaremos un conjunto de prueba extra, solo reportaremos las métricas en los grupos divididos (folds) sacados del conjunto de datos.\n","\n"],"metadata":{"id":"kM_78GgNCTnO"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import KFold\n","\n","\n","SCORING = ['accuracy','precision_macro'] # métricas de desempeño que nos interesará evaluar, podemos agregar si queremos\n","                                         # usar sklearn.metrics.SCORERS.keys() para ver las métricas disponibles\n","\n","logistic_regresion_cv = LogisticRegression(penalty=\"none\")# generamos una instancia del modelo\n","\n","CV         = KFold(n_splits = 10, shuffle = True, random_state = 1)# definimos el tipo de estrategia de validación cruzada, KFold en este caso con 10 folds y con reordanmiento aleatorio de los datos originales\n","cv_results = cross_validate(logistic_regresion_cv, penguins[culmen_columns].values, penguins[target_column].values, cv = CV,\n","                            scoring=SCORING,\n","                            return_train_score=True)# aplicamos la estrategia\n"],"metadata":{"id":"uOxxcvidAxcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualicemos los resultados\n","import pandas as pd\n","cv_results = pd.DataFrame(cv_results)\n","cv_results"],"metadata":{"id":"pj0EmXgZdDbi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Obtenemos la información de las métricas de interés y tiempos para ajustar y predecir en cada iteración de validación cruzada. También tenemos el score para prueba, el cual corresponde a un error de prueba en cada una de las divisiones."],"metadata":{"id":"93bAVHSZdpKW"}},{"cell_type":"code","source":["len(cv_results)"],"metadata":{"id":"go26zHHGdntK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En total tenemos 10 entradas en el dataframe resultante dado que definimos 10 divisiones del conjunto de datos. Por consiguiente, podemos estimar métricas promedio y su desviación estándar para tener un indicio de su variabilidad."],"metadata":{"id":"vllA-qV1eIUf"}},{"cell_type":"code","source":["print(f\"El promedio del accuracy en los conjuntos de prueba de validación cruzada es: \"\n","      f\"{cv_results['test_accuracy'].mean():.2f}\")"],"metadata":{"id":"DgP9wdMseGqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"La desviación estándar del accuracy usando validación cruzada es:\"\n","      f\"{cv_results['test_accuracy'].std():.2f}\")"],"metadata":{"id":"5IOxeUThdlCq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notamos que el accuracy es mucho más grande que la desviación estándar reportada, esto nos dice que la variabilidad del accuracy es aproximadamente del 3%.\n","\n","**Finalmente, qué modelo usamos para predecir la etiqueta de nuevas muestras?** lo que hacemos es entrenar el modelo, en este caso el de regresión logística, esta vez en todos los datos disponibles, pero considerando como métricas de desempeño las obtenidas con la estrategia anterior, esto nos da una indicación mas realista sobre como se debiera comportar el modelo en nuevos datos."],"metadata":{"id":"wadZ6uhigYGd"}},{"cell_type":"markdown","source":["### **Ejercicio complementario**"],"metadata":{"id":"z9iHwgkjAnEa"}},{"cell_type":"markdown","source":["En este problema, resolver el mismo ejercicio anterior, pero ahora considerar el conjunto de datos con las tres especies de pingüinos y todas las variables.\n","\n","**Nota:** Reportar al menos una métrica de desempeño usando validación cruzada y la matriz de confusión usando todo el conjunto de datos."],"metadata":{"id":"lUqwydltvFNz"}},{"cell_type":"markdown","source":["**Solución:**"],"metadata":{"id":"aDcj07GDvltB"}},{"cell_type":"code","source":["# Cargamos todos los datos\n","import pandas as pd\n","penguins = pd.read_csv(\"https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/datasets/penguins_classification.csv\")\n","\n","data    = penguins[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]].values\n","target  = penguins[\"Species\"].values\n","LABELS  = penguins[\"Species\"].unique()"],"metadata":{"id":"qhxC1sogAmnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aplicamos la estrategia de validación cruzada y entrenamos el modelo de regresión logística\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import KFold\n","\n","\n","lr_penguins = LogisticRegression(penalty=\"none\")# generamos una instancia del modelo\n","\n","CV         = KFold(n_splits = 10, shuffle = True, random_state = 1)\n","cv_results = cross_validate(lr_penguins, data, target, cv = CV, scoring='accuracy')# aplicamos la estrategia\n","\n","print(f\"El promedio del accuracy (y su desviación estándar) en los conjuntos de prueba de validación cruzada es: \"\n","      f\"{cv_results['test_score'].mean():.2f} ({cv_results['test_score'].std():.2f})\")"],"metadata":{"id":"PD5KJLbe8B6J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ojo, ahora como el único score que definí arriba es accuracy, se accede como `test_score` en `cv_results`. Esto se puede verificar fácilmente inspeccionado las variables generadas. Entrenemos ahora el modelo en todos los datos disponibles y despleguemos la matriz de confusión:"],"metadata":{"id":"NShE5ZO39e5o"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","lr_penguins.fit(data,target)#entrenamos el modelo en todos los datos disponibles\n","cm = confusion_matrix(target,lr_penguins.predict(data),labels = LABELS)# calculamos matriz de confusión\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm,  display_labels=LABELS)# desplegamos matriz de confusión\n","disp.plot()\n","plt.title(\"Matriz de confusión conjunto datos completo\")\n","plt.show()"],"metadata":{"id":"QBjCvN6V9TNU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Referencias**"],"metadata":{"id":"8QioAXG51OTP"}},{"cell_type":"markdown","source":["1. Cusro sci-kit learn MOOC Inria: https://inria.github.io/scikit-learn-mooc/index.html\n","2. Sci-kit learn documentación:\n","\n","* Validación cruzada: [enlace](https://scikit-learn.org/stable/modules/cross_validation.html)\n","* Regresión Logística: [enlace](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n","* Matriz de confusión: [enlace](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"],"metadata":{"id":"xG4yX7gNHWub"}}]}