{"cells":[{"cell_type":"markdown","metadata":{"id":"DV45IZ9474vp"},"source":["#**Práctica 7: Redes Neuronales Artificiales Convolucionales 1 (Evaluación)**\n","\n","Curso: Inteligencia Artificial para Ingenieros\n","\n","Prof. Carlos Toro N. (carlos.toro.ing@gmail.com)\n","\n","2022"]},{"cell_type":"markdown","source":["## **Instrucciones de la evaluación**\n","- Entregar el notebook completamente ejecutado. Este está estructurado para que sea fácil de seguir y ejecutarlo paso a paso.\n","- Resolver las preguntas planteadas en el notebook, en particular el ejercicio final planteado.\n","- Comentar siempre sus resultados.\n","\n","NOTA: asegúrese de que el hardware que usa el entorno de ejecución es una GPU. Verificar en Entorno de ejecución -> Cambiar tipo de entorno de ejecución."],"metadata":{"id":"t_xeltnxaPau"}},{"cell_type":"markdown","metadata":{"id":"gcYaBcWu8NH4"},"source":["##**Introducción**"]},{"cell_type":"markdown","source":["En esta guía implementaremos redes neuronales: completamente conectada y convolucional, para resolver el problema de clasificación de dígitos escritos a mano y de imagenes de prendas de vestir."],"metadata":{"id":"vLUwN2wmbvlc"}},{"cell_type":"markdown","source":["**Descripción del dataset**: Los datos que usaremos en esta parte del laboratorio coresponde al dataset MNIST de dígitos escritos a mano, este contiene 60000 imágenes de entrenamiento y 10000 imágenes de prueba, cada una de 28x28 pixeles en escala de grises. El dataset fue creado por el investigador Yann LeCun y se encuentra descrito en todos lados, en particular, en su referencia original:\n","\n","[Referencia del MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n","\n","<center>\n","    <img width=\"80%\" src=\"https://miro.medium.com/max/1400/1*Riqqoa7vKHXnFHvaGfDFjA.webp\">\n","</center>"],"metadata":{"id":"WAjWb_W7q0XD"}},{"cell_type":"markdown","metadata":{"id":"lMJMHb-BsmHM"},"source":["**PREVIO:** Importaciones necesarios para la práctica"]},{"cell_type":"code","source":["# Imports\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers, optimizers, datasets\n","from matplotlib import pyplot as plt\n","import numpy as np"],"metadata":{"id":"ppCfENTORh5y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Is952HwcNu_K"},"source":["##1. Implementación de un clasificador con un perceptrón multicapa o red completamente conectada."]},{"cell_type":"code","source":["# el dataset se encuentra disponible en todos lados, en particular en los datasets de tensorflow\n","help(datasets.mnist.load_data)"],"metadata":{"id":"VN2DYf93sn-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cargamos el dataset:\n","(x_train_raw, y_train_raw), (x_test_raw,y_test_raw) = datasets.mnist.load_data()"],"metadata":{"id":"v-swTL3nsxL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dimensiones de los datos\n","print(x_train_raw.shape,y_train_raw.shape)\n","print(x_test_raw.shape,y_test_raw.shape)"],"metadata":{"id":"qEG6deW9szd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cómo se encuentran codificadas las etiquetas?\n","print(y_train_raw[0:10])# ejemplo, primeras diez muestras"],"metadata":{"id":"SOIbncP1s1vl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convirtiendo las etiquetas a one-hot encodes para entrenar la red yaque la capa de salida será una softmax\n","num_classes = 10\n","y_train = keras.utils.to_categorical(y_train_raw,num_classes)\n","y_test = keras.utils.to_categorical(y_test_raw,num_classes)\n","\n","print(y_train[0])#cómo aparece ahora la salida?"],"metadata":{"id":"ERx16AOus4MB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocesamiento y visualización"],"metadata":{"id":"ZBKGoTbVs-sm"}},{"cell_type":"code","source":["# mostremos algunas imagenes del dataset\n","plt.figure(figsize=(8,5))\n","\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(x_train_raw[i],cmap='gray')\n","    plt.axis(\"off\")\n","    plt.title(\"Etiqueta: {} \".format(y_train_raw[i]))\n","plt.show()"],"metadata":{"id":"BPFc365_s9uu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convertimos las imagenes de 28x28 pixeles a vectores de  784 elementos para pasarselos a la red\n","x_train = x_train_raw.reshape(60000,784)\n","x_test  = x_test_raw.reshape(10000,784)\n","\n","# Preprocesamiento: Escalamos los valores de los pixeles para que estén en el rango de 0 a 1\n","x_train = x_train/255\n","x_test  = x_test/255"],"metadata":{"id":"3Wjg9QkcuJM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creación de un modelo DNN, Entrenamiento y Evaluación"],"metadata":{"id":"S24rs1WYtQM5"}},{"cell_type":"code","source":["# Definición del modelo\n","model_DNN = keras.Sequential([\n","                              layers.Dense(100,activation='relu',input_dim=784),\n","                              layers.Dropout(0.2),\n","                              layers.Dense(num_classes,activation='softmax')\n","                             ])\n","model_DNN.summary()"],"metadata":{"id":"a4pBel6YtRMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configuramos el entrenamiento\n","model_DNN.compile(optimizer = 'Adam', loss = keras.losses.categorical_crossentropy, metrics = ['accuracy'])\n","\n","# Entrenamos el modelo y guardamos el historial del entrenamiento para graficarlo\n","history = model_DNN.fit(x_train,y_train,\n","                        batch_size=128,\n","                        epochs=30,\n","                        validation_split = 0.1)"],"metadata":{"id":"faqiYzmouaJl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráficas del proceso de entrenamiento\n","from matplotlib import pyplot as plt\n","# Gráfica accuracy\n","plt.subplot(2, 1, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Acc. training')\n","plt.ylabel('Accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n","\n","# Gráfica de la función de pérdida\n","plt.subplot(2, 1, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"5koCEMa2uodC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resultados finales en training\n","print('Loss final en training: ',history.history['loss'][-1])\n","print('Accuracy final en training: ',history.history['accuracy'][-1])"],"metadata":{"id":"_PD9uluCurOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Preguntas:** (**1.5 puntos**)\n","1. ¿Qué se observa del proceso de entrenamiento?\n","2. ¿Se podría haber detenido el proceso de entrenamiento antes de las 30 épocas sin afectar el resultado?, qué estrategia usaría para hacer esto. Impleméntela y compare los resultados con la evaluación del modelo en el conjunto de prueba.\n","3. Simular el proceso anterior sin hacer el escalamiento en los datos, ¿se obtienen mejores o peores resultados? (ojo con las variables como se están sobre-escribiendo, ejecutar todas las lineas que sean necesarias, siempre comprobar algunos valores/resultados con las funciones que ya conoce de numpy)"],"metadata":{"id":"-KnAGC_-utmu"}},{"cell_type":"markdown","source":["**Evaluamos en conjunto de test**"],"metadata":{"id":"03O46U7DuwvY"}},{"cell_type":"code","source":["# Evaluamos en conjunto de prueba\n","score = model_DNN.evaluate(x_test,y_test, verbose=0)\n","\n","print('Loss en dataset de prueba: ',score[0])\n","print('Accuracy en dataset de prueba: ',score[1])"],"metadata":{"id":"022rGpVXuwSU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mostremos algunas muestras de imágenes con etiquetas predichas por el modelo propuesto."],"metadata":{"id":"a9DKHeuPQFT7"}},{"cell_type":"code","source":["# La siguiente linea permite devolver la clase predicha por el modelo,\n","# genera valores enteros coherentes con la codificación original\n","predicted_classes = np.argmax(model_DNN.predict(x_test), axis=-1)\n","\n","# Verifiquemos que elementos fueron correcta e incorrectamente clasificados\n","correct_indices = np.nonzero(predicted_classes == y_test_raw)[0]\n","incorrect_indices = np.nonzero(predicted_classes != y_test_raw)[0]"],"metadata":{"id":"ks3hFxFLQNZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","for i, correct in enumerate(correct_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(x_test[correct].reshape(28,28), cmap='gray')\n","    plt.title(\"Predicho {},\\nClase Real {}\".format(predicted_classes[correct], y_test_raw[correct]),fontdict={'color' : 'blue'})\n","    plt.axis('off')\n","plt.tight_layout()\n","\n","plt.figure(figsize=(10,5))\n","for i, incorrect in enumerate(incorrect_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(x_test[incorrect].reshape(28,28), cmap='gray')\n","    plt.title(\"Predicho {},\\nClase Real {}\".format(predicted_classes[incorrect], y_test_raw[incorrect]),fontdict={'color' : 'red'})\n","    plt.axis('off')\n","plt.tight_layout()"],"metadata":{"id":"U8stz_PIWfjl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Creación de modelo ocupando CNN"],"metadata":{"id":"iFne39TRvhI1"}},{"cell_type":"code","source":["#Creamos modelo de red CNN apilada con método secuencial\n","model_CNN = keras.Sequential([\n","           layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),# transformamos las imagenes para indicar que están en escala de grises, es decir, un solo canal\n","           # Primera capa CONV + Pooling\n","           layers.Conv2D(filters=16,kernel_size=5,strides=2,padding='same',activation='relu', input_shape=(28,28,1)),\n","           layers.MaxPool2D(2),\n","           # Segunda capa CONV + Pooling\n","           layers.Conv2D(filters=32,kernel_size=3, strides=1,padding='same',activation='relu'),\n","           layers.MaxPool2D(2),\n","           # Operación de flattening\n","           layers.Flatten(),\n","           # Dropout\n","           layers.Dropout(0.25),\n","           # Capa completamente conectada\n","           layers.Dense(units=128,activation='relu'),\n","           layers.Dense(units=10,activation='softmax')\n","           ])"],"metadata":{"id":"3xmNxl7hvjUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_CNN.summary()"],"metadata":{"id":"Zh6zU93yv6P0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#configuración del entrenamiento\n","model_CNN.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#entrenamiento\n","history = model_CNN.fit(x=x_train,y=y_train,\n","                        epochs=30,\n","                        batch_size=128,\n","                        validation_split = 0.1)"],"metadata":{"id":"tKrjMZ6Av8oE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráficas del proceso de entrenamiento\n","from matplotlib import pyplot as plt\n","# Gráfica accuracy\n","plt.subplot(2, 1, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Acc. training')\n","plt.ylabel('Accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n","\n","# Gráfica de la función de pérdida\n","plt.subplot(2, 1, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"Yj7hbk1EwGJl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resultados finales en training\n","print('Loss final en training: ',history.history['loss'][-1])\n","print('Accuracy final en training: ',history.history['accuracy'][-1])"],"metadata":{"id":"G20L_BbbwI2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluamos en conjunto de prueba\n","score = model_CNN.evaluate(x_test,y_test, verbose=0)\n","\n","print('Loss en dataset de prueba: ',score[0])\n","print('Accuracy en dataset de prueba: ',score[1])"],"metadata":{"id":"QF3kgiKawLmB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Preguntas:** (**1.5 puntos**)\n","1. ¿Qué indica el argumento `padding='same'`? ¿Qué otro valor podemos configurar?\n","2. ¿Qué puede decir acerca del número de parámetros que necesitamos optimizar en ambos modelos, el número de capas usadas y los resultados?\n","3. ¿Qué se observa del proceso de entrenamiento? Habrá existido sobreajuste?\n","4. ¿Se podría haber detenido el proceso de entrenamiento antes de las 30 épocas sin afectar el resultado?, implementar la misma estrategia que en el caso del primer modelo.\n","5. Para el modelo óptimo encontrado en 4, mostrar la matriz de confusión en el conjunto de datos de prueba.\n",""],"metadata":{"id":"24oC_0LKieVB"}},{"cell_type":"markdown","source":["## **Ejercicio final**: Clasificación de imágenes dataset Fashion MNIST (3 puntos)"],"metadata":{"id":"kICtyR7AwTnu"}},{"cell_type":"markdown","source":["Este dataset contiene 70000 imágenes en escala de grises en 10 categorías. Las imágenes muestran articulos de ropa individuales de baja resolución (28x28 píxeles), como se muestra aquí:\n","\n","<table>\n","  <tr><td>\n","    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n","         alt=\"Fashion MNIST sprite\"  width=\"600\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>Figura 2.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","\n","[Referencia del dataset](https://www.tensorflow.org/tutorials/keras/classification?hl=es-419)"],"metadata":{"id":"Eiz5E8ugwYwa"}},{"cell_type":"code","source":["# Imports\n","import tensorflow as tf\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"K97DTem-wWRA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importemos el dataset y hagamos algunas exploraciones iniciales"],"metadata":{"id":"6PKDVx6Zwih8"}},{"cell_type":"code","source":["fashion_mnist = tf.keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"],"metadata":{"id":"ipu9DryQwgdG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Las etiquetas del dataset están codificadas con enteros de 0 a 9, las clases correspondientes son:\n","\n","\n","<table>\n","  <tr>\n","    <th>Etiqueta</th>\n","    <th>Clase</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>T-shirt/top</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Trouser</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Pullover</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Dress</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Coat</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Sandal</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Shirt</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Sneaker</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Bag</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Ankle boot</td>\n","  </tr>\n","</table>"],"metadata":{"id":"sWz2734dwqwe"}},{"cell_type":"code","source":["# Definamos las clases\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"metadata":{"id":"BOGmI5shwpwC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Algunos datos que podemos extraer:"],"metadata":{"id":"rKtKVNMIwwlB"}},{"cell_type":"code","source":["# número de imágenes en el set de entreamiento\n","train_images.shape"],"metadata":{"id":"2xNh5VPPwv16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# número de etiquetas del conjunto de entrenamiento, claramente coinciden con el número de muestras\n","len(train_labels)"],"metadata":{"id":"C-BliUOpwzRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# valores de las etiquetas primeras 10 muestras\n","train_labels[0:10]"],"metadata":{"id":"4qwflz_Qw1Ky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set de test\n","test_images.shape"],"metadata":{"id":"81JGXrxZw4EM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ejemplo de una imagen del dataset\n","plt.figure()\n","plt.imshow(train_images[0])\n","plt.colorbar()\n","plt.grid(False)\n","plt.title(class_names[train_labels[0]])\n","plt.show()"],"metadata":{"id":"fRoQnUgiw7s4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cuántas imágenes hay por cada categoría?\n","np.unique(test_labels, return_counts=True)"],"metadata":{"id":"8vvAwPXnzn3g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Tareas a realizar:**\n","* Para resolver el problema, implementar el modelo de red neuronal LeNet-5, su arquitectura está descrita en la siguiente imagen:\n","\n","\n","<center>\n","    <img width=\"60%\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/800px-Comparison_image_neural_networks.svg.png\">\n","</center>\n","\n","[Referencia modelo LeNet-5](https://en.wikipedia.org/wiki/LeNet).\n","\n","Nota: si no se entrega la medida de stride en alguna capa, asumirlo como 1.\n","* Se recomienda implementar el entrenamiento con detención temprana.\n","* Graficar la matriz de confusión en el conjunto de prueba.\n","* Graficar muestras de imágenes bien y mal clasificadas con las etiquetas predichas por el modelo.\n","\n","TIP: cuando implementen el modelo, mostrarlo con el método `summary()` para verificar que las dimensiones de salida coinciden con las de la imagen."],"metadata":{"id":"7IFBdU0OxAly"}},{"cell_type":"code","source":["#Su código aquí"],"metadata":{"id":"8fUSttL7j51V"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPih/16I0ULxaGIAA/6mbgX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}